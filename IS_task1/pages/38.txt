Зима искусственного интеллекта — Википедия Зима искусственного интеллекта Материал из Википедии — свободной энциклопедии Перейти к навигации Перейти к поиску Зима искусственного интеллекта — период в истории исследований искусственного интеллекта , связанный с сокращением финансирования и общим снижением интереса к проблематике [ 1 ] . Термин был введён по аналогии с термином « ядерная зима » [ 2 ] . Направление искусственного интеллекта прошло несколько циклов, сопровождавшихся повышенным ажиотажем, сменяющихся «зимами» — разочарованием, критикой и последующим сокращением финансирования, а затем возобновлением интереса несколько лет или десятилетий спустя [ 3 ] . Термин впервые упомянут в 1984 году на ежегодной встрече AAAI (Американской ассоциации искусственного интеллекта): на одном из обсуждений Роджер Шэнк [англ.] и Марвин Мински — два ведущих исследователя в области искусственного интеллекта — предупредили бизнес-сообщество, что энтузиазм в отношении направления вышел из-под контроля, и что за ним последует разочарование, иллюстрацией послужила «первая зима» направления, пережитая в 1970-х годах. После этого обсуждения последовала цепная реакция, сопровождающаяся пессимизмом в среде исследователей, распространившаяся также в СМИ, и в конечном итоге приведшая к снижению финансирования и остановке крупных работ [ 2 ] ; три года спустя миллиардная индустрия искусственного интеллекта была фактически обрушена [ 2 ] . Как для всякого ажиотажа, сопутствующего перспективным технологиям, и характеризующимся последующими спадами ( железнодорожная мания , пузырь доткомов ), «зи́мы искусственного интеллекта» в первую очередь означали крах в восприятии лиц, принимающих решения о финансировании — правительственных чиновников, инвесторов, венчурных капиталистов, руководителей организаций. При этом, несмотря на взлёт и падение репутации искусственного интеллекта, исследования в этой области велись непрерывно, и после спадов интерес инвесторов возобновлялся по мере очередных результатов. Так, в 2005 году Рэй Курцвейл отмечал, что «зима искусственного интеллекта» не прервала работ в этой области, и уже к середине 2000-х годов «многие тысячи приложений искусственного интеллекта глубоко встроены в инфраструктуру каждой отрасли» [ 4 ] . Содержание 1 Периодизация 2 Ранние эпизоды 2.1 Машинный перевод и отчет ALPAC 1966 года 2.2 Отказ от коннективизма в 1969 году 3 Неудачи 1974 года 3.1 Отчет Лайтхилла 3.2 Сокращение финансирования DARPA в начале 1970-х 3.3 Провал SUR 4 Неудачи конца 1980-х и начале 1990-х годов 4.1 Крах рынка лисп-машин в 1987 году 4.2 Падение популярности экспертных систем 4.3 Фиаско компьютеров пятого поколения 4.4 Сокращение Инициативы стратегических вычислений 5 События после зимы ИИ 5.1 Репутация 5.2 Распространение 5.3 Финансирование 5.4 Опасения новой зимы 5.5 Наступление весны 6 Причина возникновения 6.1 Ажиотаж 6.2 Организационные причины 6.3 Экономические причины 6.4 Недостаток вычислительных мощностей 6.5 Пустой конвейер 6.6 Неспособность адаптироваться 7 Дебаты о прошлом и будущем ИИ 8 Примечания 9 Литература Периодизация [ править | править код ] Две длительные «зимы» относят к периодам 1974—1980 годов и 1987—1993 годов [ 5 ] [ 6 ] . Кроме того, было несколько менее значительных эпизодов, повлиявших на снижение интереса к направлению, среди таковых провал проектов по машинному переводу в 1966 году и неудача концепции коннекционизма в 1970 году.
Другие периоды спада интереса: 1971—1975: разочарование DARPA исследовательской программой по распознаванию речи в Университете Карнеги — Меллона ; 1973: значительное сокращение исследований по искусственному интеллекту в Великобритании в ответ на отчёт Лайтхилла ; 1973—1974: сокращение расходов DARPA на академические исследования по искусственному интеллекту в целом; 1987: крах рынка лисп-машин ; 1988: отмена новых расходов на искусственный интеллект в рамках стратегической инициативы в области компьютерной техники; 1993: экспертные системы медленно достигают экономического дна; 1990-е годы: проект создания компьютеров пятого поколения не достиг своих целей. Ранние эпизоды [ править | править код ] Машинный перевод и отчет ALPAC 1966 года [ править | править код ] Брифинг для вице-президента США Джеральда Форда в 1973 году на тему перевода с помощью модели, основанной на junction grammar Во время холодной войны правительство США было особенно заинтересовано в автоматическом, мгновенном переводе русских документов и научных докладов. Начиная с 1954 года, правительство США приложило много усилий для разработки машинного перевода. Вначале исследователи были оптимистичны: новая работа Ноама Хомского по грамматике упрощала процесс перевода, и было «много предсказаний приближающегося прорыва» [ 7 ] . Однако исследователи недооценили сложность разрешения лексической многозначности . Для того чтобы перевести предложение без ошибок, машина должна была иметь представление, о чём идет речь в предложении. Согласно мифу [ 8 ] , фраза «the spirit is willing but the flesh is weak» (крепок дух, но немощна плоть) при переводе на русский и потом обратно на английский превратилась в «the vodka is good but the meat is rotten» (водка хорошая, но мясо протухло) [ 9 ] , а «out of sight, out of mind» (с глаз долой, из сердца вон) — в «blind idiot» (слепой идиот). Позже исследователи назовут это проблемой здравого смысла [англ.] . В 1964 году Национальный исследовательский совет (NRC) США забил тревогу из-за отсутствия прогресса и создал Консультативный комитет по автоматической обработке языков [англ.] (ALPAC) для изучения этой проблемы. В своем отчете 1966 года комитет пришел к выводу, что машинный перевод оказался более дорогим, менее точным и более медленным, чем человеческий перевод. Потратив около 20 миллионов долларов, NRC свернул все разработки, а исследования были прекращены [ 10 ] [ 7 ] . В XXI веке машинный перевод так и остается открытой проблемой, хотя и решённой с некоторым успехом ( Google Translate , Yahoo Babel Fish , Яндекс Переводчик ). Отказ от коннективизма в 1969 году [ править | править код ] В ряде первых работ по ИИ для имитации разумного поведения применялись сети или схемы из соединенных между собой блоков. Примерами такого подхода, названного коннекционизмом , являются первое описание искусственной нейронной сети Уолтера Питтса и Уоррена Мак-Каллока , а также работа Марвина Минского по системе SNARC [англ.] . В конце 1950-х годов большинство этих подходов были отброшены, когда исследователи начали исследовать символьные рассуждения (symbolic reasoning) в качестве основы интеллекта после успеха таких программ, как Logic Theorist [англ.] и General Problem Solver [ 11 ] . Однако работа в одном из направлений коннекционизма продолжалась — изучение перцептрона , предложенного Фрэнком Розенблаттом , которому удавалось поддерживать исследования в этой области благодаря своим способностям «продавца» и силы своей личности [ 12 ] . Он оптимистично прогнозировал, что перцептрон «со временем сможет учиться, принимать решения и переводить языки» [ 13 ] . Основные исследования перцептронов резко прекратились в 1969 году после публикации Марвином Минским и Сеймуром Пейпертом книги « Перцептроны », которая обозначила пределы возможностей перцептронов. Коннективизм был забыт на несколько последующих десятилетий. Хотя важная работа в этом направлении частично продолжалась, например, был предложен метод обратного распространения ошибки , однако найти достаточное финансирование для проектов коннекционистов в 1970-х и начале 1980-х годов было трудно [ 14 ] . «Зима» исследований коннекционистов прекратилась в середине 1980-х годов, когда работы Джона Хопфилда , Дэвида Румельхарта и других возродили масштабный интерес к нейронным сетям [ 15 ] . Розенблатт не дождался этого, он погиб в результате несчастного случая вскоре после публикации книги «Перцептроны» [ 13 ] . Неудачи 1974 года [ править | править код ] Отчет Лайтхилла [ править | править код ] В 1973 году британский парламент поручил профессору сэру Джеймсу Лайтхиллу оценить состояние исследований искусственного интеллекта в Великобритании. Его отчет, известный как отчет Лайтхилла , раскритиковал полную неспособность ИИ достичь своих «грандиозных целей». Он пришел к выводу, что все то, что может делать ИИ, может быть сделано также другими науками. Он особенно выделил проблемы « комбинаторного взрыва » и « трудноразрешимости », которые показывали, что большинство самых успешных алгоритмов ИИ годятся лишь для решения «игрушечных» задач, а на реальных практических задачах они не работают [ 16 ] . Отчет был оспорен в дебатах, которые транслировались на канале BBC в программе «Controversy» в 1973 году. В дебатах «Универсальный робот — это мираж» Лайтхилл, представлявший Королевский Институт, дискутировал против команды из Дональда Мичи [англ.] , Джона Маккарти и Ричарда Грегори [англ.] [ 17 ] . Позже Маккарти писал, что «проблема комбинаторного взрыва была признана в ИИ с самого начала» [ 18 ] . Отчет Лайтхилла привел к прекращению большинства исследований в сфере ИИ в Великобритании [ 16 ] . Исследования продолжалось лишь в нескольких университетах второго эшелона ( Эдинбург , Эссекс и Сассекс ). Джеймс Хендлер [англ.] пишет: «Это создало эффект волны, который привел к сокращению финансирования разработок ИИ по всей Европе» [ 19 ] . Крупномасштабные исследования возобновились только в 1983 году, когда британский проект Элви [англ.] , созданный в ответ на японский проект компьютеров пятого поколения , начал финансировать в ИИ из военного бюджета в размере 350 миллионов фунтов стерлингов. Элви имел ряд требований, которые касались только Великобритании, что не подходило международным партнерам, особенно американским, и стало причиной прекращения финансирования второго этапа. Сокращение финансирования DARPA в начале 1970-х [ править | править код ] В течение 1960-х годов Агентство передовых оборонных исследовательских проектов (тогда известное как «ARPA», теперь «DARPA») выделило миллионы долларов на исследования искусственного интеллекта практически без каких-либо условий. Директор DARPA в те годы, Джозеф Ликлайдер верил в «финансирование людей, а не проектов» [ 13 ] и позволял лидерам отрасли ИИ (таким как Марвин Минский , Джон Маккарти, Герберт А. Саймон и Аллен Ньюэлл ) тратить их почти на любые цели. Ситуация переменилась после принятия поправки Мэнсфилда в 1969 году, которая требовала от DARPA финансирования «целевых исследований, а не общих ненаправленных исследований» [ 20 ] Ненаправленные общие исследования характерные 1960-м перестали финансироваться DARPA, теперь исследователи должны были показать, что их работа вскоре принесет пользу в виде новых военных технологий. Отныне предложения исследователей искусственного интеллекта рассматривались по очень строгим стандартам. Ситуация ещё больше осложнилась после выхода отчета Лайтхилла и собственного исследования DARPA (American Study Group), которые показали, что большинство исследований искусственного интеллекта вряд ли принесут хоть какую-либо пользу в обозримом будущем. В итоге деньги DARPA были направлены на проекты с более четкими целями, такие как автономные танки и системы управления боем. К 1974 году было трудно найти финансирование для проектов искусственного интеллекта [ 20 ] . Исследователь ИИ Ханс Моравек обвинил в кризисе нереалистичные прогнозы своих коллег: «Многие исследователи оказались в паутине все большего преувеличения. Первые обещания, данные им DARPA, были слишком оптимистичными. Конечно, то, что они разрабатывали в результате, значительно отличалось от обещаний. Но они считали, что в следующий раз не могут пообещать меньше, чем в первый, поэтому обещали ещё больше» [ 13 ] . В результате сотрудники DARPA потеряли терпение к исследованиям ИИ, как утверждает Моравек. Моравек сообщил Дэниелу Кревьеру [англ.] , что «в DARPA буквально сказали: некоторых из этих людей следует проучить, сократив их контракты на два миллиона долларов в год почти до нуля!» [ 13 ] . Хотя проект автономного танка провалился, система управления боем (Dynamic Analysis and Replanning Tool, DART) оказалась чрезвычайно успешной и сэкономила миллиарды долларов во время первой войны в Персидском заливе , таким образом компенсируя все инвестиции DARPA в ИИ [ 21 ] и тем самым оправдав прагматичную политику DARPA [ 22 ] . Провал SUR [ править | править код ] DARPA оказалась глубоко разочарованной исследователями из университета Карнеги-Меллона, работавшими над программой распознавания речи. В DARPA рассчитывали получить, и считали, что им обещали предоставить, систему голосового управления для пилотов. Команда SUR разработала систему, которая могла распознать разговорный английский язык, но только если слова были произнесены в определённом порядке. В DARPA посчитали, что их обманули, и в 1974 году они отменили грант в размере 3 миллиона долларов в год [ 23 ] . Много лет спустя успешные коммерческие системы распознавания речи будут использовать технологии, разработанные командой Карнеги-Меллона (такие как скрытые марковские модели ), и в 2001 году рынок систем распознавания речи достигнет 4 млрд долларов [ 24 ] . Неудачи конца 1980-х и начале 1990-х годов [ править | править код ] Крах рынка лисп-машин в 1987 году [ править | править код ] В 1980-х корпорации по всему миру взяли на вооружение экспертные системы (форма искусственного интеллекта). Первой коммерческой экспертной системой была XCON , разработанная в университете Карнеги-Меллона для корпорации Digital Equipment . Имевшая огромный успех, она помогла Digital Equipment сэкономить, по оценкам, 40 миллионов долларов за шесть лет работы. Корпорации по всему миру начали разрабатывать и внедрять экспертные системы, к 1985 году они тратили на ИИ свыше миллиарда долларов, большая часть которых направлялась на внутренние отделы искусственного интеллекта. Для того чтобы удовлетворить эти потребности выросла целая индустрия, в которую входили разработчики программ, такие как Teknowledge и Intellicorp (KEE) [англ.] , и производители оборудования, такие как Symbolics [англ.] и Lisp Machines Inc [англ.] . Они создали специализированные компьютеры для ИИ, лисп-машины , оптимизированные для обработки языка программирования Lisp , в то время наиболее предпочтительного в области разработки ИИ [ 13 ] . В 1987 году, через три года после прогноза Минского и Шанка, рынок лисп-машин рухнул. Рабочие станции таких компаний, как Sun Microsystems , предлагали мощную альтернативу лисп-машинам, а такие компании, как Lucid Inc. , предложили среду LISP для этого нового класса рабочих станций. Производительность рабочих станций общего назначения становилась всё более трудным вызовом для лисп-машин. Такие компании, как Lucid Inc. и Franz Inc , предлагали всё более мощные версии LISP. Результаты бенчмарков показали, что рабочие станции превосходят в производительности лисп-машины [ 25 ] . Позже настольные компьютеры Apple и IBM также предложат более простую и популярную архитектуру для запуска LISP-приложений. К 1987 году они стали мощнее, чем более дорогие лисп-машины. На настольных компьютерах были доступны движки на основе правил, такие как CLIPS [ 26 ] . Эти альтернативы не оставили потребителям причин покупать дорогие лисп-машины. Вся отрасль лисп-машин стоимостью полмиллиарда долларов исчезла за один год [ 13 ] . С коммерческой точки зрения многие Lisp-компании обанкротились, как например Symbolics, Lisp Machines Inc., Lucid Inc. и др. Другие компании, такие как Texas Instruments , и Xerox , ушли из отрасли. Ряд компаний-клиентов, тем не менее, продолжали использовать и поддерживать системы, написанные на Lisp и разработанные на лисп-машинах. Падение популярности экспертных систем [ править | править код ] В начале 1990-х годов первые успешные экспертные системы, такие как XCON, оказались слишком дорогими в обслуживании. Их было сложно обновлять, они не могли обучаться, они были «хрупкими» (делали нелепые ошибки при получении необычных входных данных). Также они стали жертвой проблем (таких как проблема квалификации [англ.] ), обнаруженных при исследовании немонотонной логики. Экспертные системы доказали свою эффективность лишь в нескольких особых контекстах [ 1 ] . Другая проблема касалась вычислительной сложности задачи поддержки истинности [англ.] относительно общих знаний. KEE использовал подход на основе предположений (см. NASA, TEXSYS [ 27 ] ), поддерживающий сценарии множественных миров [ 27 ] , который был труден для понимания и применения. Небольшое количество компаний, оставшихся в области экспертных систем, в конце концов были вынуждены сократить штаты и искать новые рынки и программные парадигмы, такие как рассуждения на основе прецедентов или универсальный доступ к базе данных . Развитие Common Lisp спасло много систем, таких как ICAD , которые нашли применение в инженерии на основе знаний. Другие системы, такие как KEE Intellicorp, перешли с Lisp на C++ на ПК и помогли в становлении объектно-ориентированных технологий (в том числе внесли большой вклад в разработку UML ). Фиаско компьютеров пятого поколения [ править | править код ] В 1981 году японское министерство международной торговли и промышленности [англ.] выделило 850 миллионов долларов на проект компьютеров пятого поколения . Его задачей было создание программ и машин способных поддерживать разговор, переводить языки, понимать изображения и размышлять как люди. К 1991 году впечатляющий список целей, составленный в 1981 году, не был выполнен, а некоторые из них не были выполнены ни в 2001, ни в 2011 годах. Как и в других проектах ИИ, ожидания были гораздо больше, чем возможности их реализовать [ 13 ] . Сокращение Инициативы стратегических вычислений [ править | править код ] В 1983 году DARPA в ответ на проект пятого поколения возобновили финансирование исследований искусственного интеллекта, запустив Инициативу стратегических вычислений (Strategic Computing Initiative). Проект предполагалось начать с практических, достижимых целей, одной из которых был искусственный интеллект в долгосрочной перспективе. Программа находилась под руководством Управления технологий обработки информации [англ.] (IPTO), а также была направлена на суперкомпьютеры и микроэлектронику . К 1985 году на программу было потрачено 100 миллионов долларов, в 60 учреждениях было запущено 92 проекта, из них половина в промышленности, другая половина в университетах и правительственных лабораториях. Исследования искусственного интеллекта щедро финансировались SCI [ 11 ] . В 1987 году руководителем IPTO стал Джек Шварц, который отверг экспертные системы как «умелое программирование» и «глубоко и жестко» сократил финансирование ИИ, «лишая содержания» SCI. Шварц не считал ИИ «новой волной» и хотел, сосредоточить финансирование DARPA только на самых перспективных технологиях, по его словам, DARPA должна «кататься на серфе», а не «плавать по-собачьи». Кроме того, сотрудники программы сообщали о проблемах в коммуникации, организации и интеграции. Только несколько проектов пережили сокращение финансирования: помощник пилота, беспилотное наземное транспортное средство (так и не было создано) и система управления боем DART (как отмечалось выше, стала успешной) [ 11 ] . События после зимы ИИ [ править | править код ] Репутация [ править | править код ] Обзор отчетов середины 2000-х годов свидетельствует о том, что репутация ИИ все ещё была небезупречной: Алекс Кастро в The Economist , 2007: «Термин „распознавание голоса“ отталкивает инвесторов, подобно „искусственному интеллекту“ он ассоциируется с ложными обещаниями» [ 28 ] Патти Таскарелла в Pittsburgh Business Times [англ.] , 2006: «Некоторые считают, что слово „робототехника“ отмечено клеймом, снижающим шансы компании на финансирование» [ 29 ] Джон Маркофф [англ.] в Нью-Йорк Таймс , 2005: «В худшие для ИИ времена, ряд компьютерных специалистов и программистов избегал термина „искусственный интеллект“ из страха прослыть безумцами» [ 30 ] . Многие исследователи в середине 2000-х годов намеренно избегали термина ИИ и использовали для своей деятельности другие названия, такие как информатика , машинное обучение , аналитика, системы, основанные на знании [англ.] , система управления бизнес-правилами , когнитивные системы , интеллектуальные системы , интеллектуальные агенты , вычислительный интеллект , чтобы подчеркнуть применение конкретных инструментов или показать направленность на конкретную задачу более низкого уровня. Хотя ученые и могли считать свою область деятельности принципиально отличной от ИИ, новые названия помогали получить финансирование, поскольку были лишены того клейма невыполненных обещаний, с которым ассоциировался «искусственный интеллект» [ 30 ] . Распространение [ править | править код ] Рэй Курцвейл писал в 2005 году: «Многие эксперты все ещё считают, что зима ИИ стала концом отрасли и с тех пор ИИ не дал практических результатов, однако уже сегодня существуют тысячи приложений ИИ во всех отраслях и они глубоко вплетены в их инфраструктуру» [ 31 ] . В конце 1990-х и начале XXI века технологии ИИ широко использовались в составе различных систем [ 32 ] [ 31 ] , правда, их успех почти никогда не приписывался ИИ. В 2006 году Ник Бостром пояснил, что «в повсеместное употребление вошло много передовых технологий ИИ часто без какого-либо упоминания ИИ вообще, поскольку когда что-либо становится достаточно полезным или распространенным, оно перестает называться ИИ». Родни Брукс примерно в то же время сказал: «существует этот глупый миф, что ИИ не оправдал надежд, но ИИ каждую секунду повсюду вокруг вас» [ 33 ] . Технологии ИИ достигли коммерческого успеха в таких областях, как машинный перевод, добыча данных , промышленная робототехника , логистика [ 21 ] , распознавание речи, банковское программное обеспечение, медицинская диагностика и поисковая система Google [ 34 ] . Были разработаны контроллеры нечеткой логики для автоматических коробок передач в автомобилях. В 2006 году Audi TT, VW Touareg и VW Caravell оснащены коробкой передач DSP, которая использует нечеткую логику. Ряд моделей Skoda ( Skoda Fabia ) используют контроллеры с нечеткой логикой. Нечеткая логика широко используется в датчиках камер для фокусировки. Эвристический поиск и анализ данных развились из входящих в сферу искусственного интеллекта, эволюционного моделирования и машинного обучения. И снова эти технологии достигли значительного коммерческого успеха на широком круге реальных задач. Например, эвристический поиск использовался для составления графика работы магазинов и планирования рабочего графика для 20 000 инженеров. Анализ данных вместе с алгоритмами автоматизированного формирования классификаторов, разработанных в 1990-х годах исследователями в области машинного обучения с учителем (например, TDIDT, Support Vector Machines, Neural Nets, IBL), сейчас широко применяется для таргетинга маркетинговых опросов, выявления трендов и признаков (фич) в наборах данных. Финансирование [ править | править код ] Исследователи и экономисты оценивают положение дел в ИИ, в основном, по тому, какие проекты ИИ финансируются, кем и в каких объёмах. Тренды в финансировании часто задают крупные финансовые учреждения в развитых странах мира. В настоящее время значительную часть финансирования для исследований ИИ в США и Европейском Союзе обеспечивают DARPA и гражданская программа финансирования EU-FP7 . На 2007 год DARPA рассматривала предложения исследователей ИИ в рамках ряда программ, в числе которых The Grand Challenge Program [англ.] , Cognitive Technology Threat Warning System [англ.] (CT2WS), «Human Assisted Neural Devices (SN07-43)», «Autonomous Real-Time Ground Ubiquitous Surveillance-Imaging System (ARGUS-IS)» и «Urban Reasoning and Geospatial Technology Exploitation (URGENT)». Вероятно, самой известной является программа DARPA «The Grand Challenge Program» [ 35 ] , по которой были разработаны полностью автоматизированные дорожные транспортные средства способные в автономном режиме успешно перемещаться по реальной местности [ 36 ] . DARPA также поддерживает программы по семантической паутине , уделяя большое внимание интеллектуальному управлению контентом и автоматизированному пониманию. Однако Джеймс Хендлер [англ.] , менеджер программы DARPA, выразил разочарование способностью правительства совершать быстрые изменения и перешел к сотрудничеству с консорциумом Всемирной паутины , чтобы передать технологии в частный сектор. Программа финансирования ЕС-FP7 оказывает поддержку исследователям Европейского Союза. В 2007—2008 годах она финансировала исследования ИИ по программам: «Когнитивные системы: взаимодействие и робототехника» (193 млн евро), «Цифровые библиотеки и цифровой контент» (203 млн евро), FET (185 млн евро) [ 37 ] . Опасения новой зимы [ править | править код ] Иногда высказывают опасения, что новую зиму ИИ могут вызвать чрезмерно амбициозные или нереалистичные обещания известных ученых в области ИИ или чрезмерными обещаниями коммерческих поставщиков. Например, в начале 1990 года исследователи опасались, что к зиме ИИ приведет широкая огласка планов Cog [англ.] создать интеллект уровня двухлетнего ребёнка. Джеймс Хендлер в 2008 году отметил, что финансирование ИИ, как в ЕС, так и в США, перенаправлялось больше на прикладные области и кросс-научные исследования с традиционными науками, такими как биоинформатика [ 26 ] . Этот отход от фундаментальных исследований происходит, поскольку существует тенденция к переходу в практические приложения, например, такие как семантическая паутина . Ссылаясь аргумент конвейера (см. Причины), Хендлер увидел параллель с зимой 1980-х годов и предупредил о наступлении зимы ИИ в 2010-м. Наступление весны [ править | править код ] В прошлом появлялись постоянные сообщения о том, что ещё одна весна ИИ неизбежна или уже наступила: Радж Редди в президентском обращении к AAAI, 1988: «Отрасль впечатляет как никогда. Наши последние достижения значительны и существенны. Мифическая зима ИИ, возможно, превратилась в весну ИИ. Я вижу, как расцветают цветы» [ 38 ] Памела МакКордак в «Machines Who Think»: «В 1990-х годах зеленые ростки пробились через зимнюю почву» [ 11 ] Джим Хендлер и Девика Субраманьян в «AAAI Newsletter», 1999: «Весна здесь! В отличие прошлого десятилетия с зимой ИИ, сейчас — лучшее время работать в сфере ИИ» Рэй Курцвейл в своей книге «Сингулярность близко», 2005: «Зима ИИ уже давно закончилась» [ 33 ] Хизер Хальвенштейн в «Computerworld», 2005: «Сейчас исследователи просыпаются из того, что называлось „зима ИИ“» Джон Маркофф в «Нью-Йорк Таймс», 2005: «Сегодня исследователи говорят о весне ИИ» [ 30 ] Джеймс Хендлер, в редакции выпуска «IEEE Intelligent Systems» за май-июнь (( Hendler 2007 )): «Где все эти интеллектуальные агенты сейчас?» В настоящее время заметное увеличение финансирования ИИ, его разработки, внедрения и коммерческого использования привело к тому, что зима ИИ давно закончилась [ 39 ] . Причина возникновения [ править | править код ] Было предложено несколько объяснений зим ИИ. Чаще всего причиной зим называют ажиотаж, но также действовали и другие факторы, которые приведены ниже. Однако с переходом финансирования ИИ от правительств к коммерческим организациям в действие вступила новая динамика. Ажиотаж [ править | править код ] Зиму ИИ можно рассматривать как крах вследствие слишком раздутых ожиданий, сравнимый с экономическими пузырями на фондовом рынке, например железнодорожная мания или пузырь доткомов . В общей модели развития новых технологий (известной как цикл ажиотажа ) любое событие, такое как технологический прорыв, на первых порах создает широкий общественный интерес, который подпитывает сам себя и создает «пик чрезмерных ожиданий». За ним идет «избавление от иллюзий», иными словами крах, поскольку усилия ученых и инженеров не поспевают за перегретыми ожиданиями инвесторов и других заинтересованных сторон. Технологии ИИ подтвердили эту модель развития. Организационные причины [ править | править код ] Ещё одним фактором послужило место ИИ в организации университетов. Исследования по ИИ часто принимают форму междисциплинарных исследований [англ.] , в проектах могут быть задействованы специалисты из областей от философии и до машиностроения . Ввиду этого ИИ подвержен типичным болезням междисциплинарных исследований. Так, при сокращении финансирования факультеты будут урезать неосновные направления, к которым относятся междисциплинарные и необычные исследовательские проекты, то есть ИИ. Экономические причины [ править | править код ] Во время экономических спадов правительства сокращают университетские бюджеты, организационная причина усиливается ещё больше. Инвесторы в кризисное время выбирают для вложений менее рискованные проекты, чем ИИ. Все вместе это превращает экономический кризис в зиму ИИ. Доклад Лайтхилла вышел в период экономического кризиса в Великобритании [ 40 ] , когда университетам приходилось выбирать, какие проекты пустить под нож. Недостаток вычислительных мощностей [ править | править код ] Потенциал нейронных сетей хорошо осознавался, но так и не был реализован из-за начального этапа развития вычислительной техники. Даже по современным стандартам достаточно простые сети требуют немалые вычислительные мощности. Пустой конвейер [ править | править код ] Связь между фундаментальными исследованиями и технологиями часто представляют как конвейер. Достижения в фундаментальных исследованиях порождают успехи в прикладных исследованиях, а они, в свою очередь, приводят к новым коммерческим применениям. Поэтому недостаток фундаментальных исследований приводит через несколько лет в будущем к сокращению рынка технологий. Такую точку зрения выдвинул Джеймс Хендлер в 2008 году [ 26 ] , он высказал мнение, что провал экспертных систем в конце 1980-х был вызван не присущей им ненадежностью, а сокращением финансирования фундаментальных исследований в 1970-х. Экспертные системы появились в 1980-х годах благодаря прикладным исследованиям, но к концу десятилетия конвейер пустовал, поэтому недостатки экспертных систем не удалось устранить, тем самым оказалось невозможно обеспечить и дальнейшее финансирование. Неспособность адаптироваться [ править | править код ] Крах рынка LISP-машин и провал компьютеров пятого поколения — примеры, когда дорогие передовые продукты проиграли более простым и более дешёвым конкурентам. Эта ситуация попадает под определение дешевых подрывных инноваций , поскольку производители LISP-машин были отодвинуты на второй план. Экспертные системы пережили смену машин, их перенесли на новые настольные компьютеры, например, с помощью CLIPS , откуда становится ясно, что крах рынка LISP-машин и крах экспертных систем — это два разных события. Неспособность адаптироваться к такому изменению на рынке вычислительных машин считается одной из причин зимы 1980-х [ 26 ] . Дебаты о прошлом и будущем ИИ [ править | править код ] Философы, когнитивисты , компьютерные специалисты размышляют о том, где ИИ потерпел неудачу и что с ним будет в будущем. Хьюберт Дрейфус подчеркивал ошибочность предположений об исследованиях в области ИИ [англ.] в прошлом и ещё в 1966 году правильно предсказал, что первая волна исследований ИИ не сможет выполнить те самые публичные обещания, которые она даёт. Другие критики, такие как Ноам Хомский, утверждали, что ИИ двигается в неправильном направлении, в частности из-за сильной зависимости от статистических методов [ 41 ] . Замечания Хомского вписываются в большую дискуссию с Питером Норвигом о роли статистических методов в ИИ. Спор между учеными начался с комментариев Хомского на симпозиуме в Массачусетском технологическом институте [ 42 ] , на которые Норвиг написал ответ [ 43 ] . Примечания [ править | править код ] ↑ 1 2 AI Expert Newsletter: W is for Winter Архивировано 9 ноября 2013 года. ↑ 1 2 3 Crevier, Daniel. AI: The Tumultuous Search for Artificial Intelligence. — 1993. — С. 203. — ISBN 0-465-02997-3 . ↑ Kaplan Andreas; Michael Haenlein (2018) Siri, Siri in my Hand, who’s the Fairest in the Land? On the Interpretations, Illustrations and Implications of Artificial Intelligence, Business Horizons, 62(1) (неопр.) . Дата обращения: 25 ноября 2018. Архивировано из оригинала 21 ноября 2018 года. ↑ Kurzweil, Ray. The Singularity is Near . — Viking Press. — 2005. ↑ J. Howe. Artificial Intelligence at Edinburgh University : a Perspective (неопр.) (ноябрь 1994). Архивировано 17 августа 2007 года. : «отчёт Лайтхилла [1973] вызвал массовую потерю доверия к ИИ со стороны академического истеблишмента в Великобритании (и в меньшей степени в США). Он сохранялся в течение десятилетия ― так называемая „зима AI“» ↑ Stuart J. Russell , Peter Norvig (2003), Artificial Intelligence: A Modern Approach (2nd ed.), Upper Saddle River, New Jersey: Prentice Hall, p. 24, ISBN 0-13-790395-2 , Архивировано 28 февраля 2011 , Дата обращения: 5 ноября 2018 {{ citation }} :  Википедия:Обслуживание CS1 (множественные имена: authors list) ( ссылка ) Источник (неопр.) . Дата обращения: 5 ноября 2018. Архивировано 28 февраля 2011 года. : «в целом, индустрия искусственного интеллекта выросла с нескольких миллионов долларов в 1980 году до миллиардов долларов в 1988 году. Вскоре после этого наступил период, названный „зимой ИИ“» ↑ 1 2 John Hutchins 2005 The history of machine translation in a nutshell. Архивная копия от 13 июля 2019 на Wayback Machine ↑ Hutchins, John. 1995. «The whisky was invisible», or Persistent myths of MT. Retrieved from http://www.hutchinsweb.me.uk/MTNI-11-1995.pdf Архивная копия от 4 апреля 2020 на Wayback Machine ↑ Russell, Norvig, 2003 , p. 21. ↑ Crevier, 1993 , p. 203. ↑ 1 2 3 4 McCorduck, 2004 ↑ Pamela McCorduck процитировала одного коллегу: «Он был мечтой для пресс-службы, настоящим шаманом.» ( McCorduck 2004 ) ↑ 1 2 3 4 5 6 7 8 Crevier, 1993 ↑ Crevier, 1993 , McCorduck, 2004 , Russell & Norvig, 2003 ↑ Crevier, 1993 and Russell & Norvig, 2003 ↑ 1 2 Crevier, 1993 , Russell & Norvig, 2003 , Howe, 1994 and see also Lighthill, 1973 ↑ BBC Controversy Lighthill debate 1973 (неопр.) . BBC "Controversy" debates series . ARTIFICIAL_INTELLIGENCE-APPLICATIONS¯INSTITUTE. Дата обращения: 13 августа 2010. Архивировано 1 мая 2013 года. ↑ McCarthy, John. Review of the Lighthill Report (неопр.) . Дата обращения: 10 сентября 2008. Архивировано 30 сентября 2008 года. ↑ Hendler, James. Avoiding Another AI Winter (неопр.) . Архивировано 12 февраля 2012 года. ↑ 1 2 NRC, 1999 (разделы до 1980) ↑ 1 2 Russell & Norvig, 2003 ↑ NRC, 1999 ↑ Crevier, 1993 (on whom this account is based). Other views include McCorduck, 2004 and NRC, 1999 under «Success in Speech Recognition» ↑ NRC, 1999 under «Success in Speech Recognition» ↑ Brooks, Rodney. Design of an Optimizing, Dynamically Retargetable Compiler for Common LISP (неопр.) . Lucid, Inc.. Архивировано 20 августа 2013 года. ↑ 1 2 3 4 Avoiding another AI Winter Архивная копия от 12 февраля 2012 на Wayback Machine , James Hendler, IEEE Intelligent Systems (March/April 2008 (Vol. 23, No. 2) pp. 2-4 ↑ 1 2 Building Human Interfaces to Fault Diagnostic Expert Systems I: Designing the Human Interface to Support Cooperative Fault Diagnosis ↑ Alex Castro in Are you talking to me? The Economist Technology Quarterly (7 June 2007) Архивировано {{{2}}}. ↑ Robotics firms find fundraising struggle, with venture capital shy . By Patty Tascarella. Pittsburgh Business Times (11 August 2006) Архивировано {{{2}}}. ↑ 1 2 3 Markoff, John (14 октября 2005). Behind Artificial Intelligence, a Squadron of Bright Real People . The New York Times . Дата обращения: 30 июля 2007 . ↑ 1 2 Kurzweil, 2005 , p. 264. ↑ NRC, 1999 under «Artificial Intelligence in the 90s» ↑ 1 2 Kurzweil, 2005 , p. 263. ↑ For the use of AI at Google, see Google’s man behind the curtain , Google backs character recognition Архивная копия от 14 июля 2014 на Wayback Machine and Spying an intelligent search engine Архивная копия от 14 июля 2014 на Wayback Machine . ↑ Grand Challenge Home Архивировано 24 декабря 2010 года. ↑ DARPA Архивировано 6 марта 2009 года. ↑ Information and Communication Technologies in FP7 (недоступная ссылка) , overview document for European Union funding. Retrieved 20 September 2007. ↑ Reddy, Raj. Foundations and Grand Challenges of Artificial Intelligence (неопр.) . Association for the Advancement of Artificial Intelligence (1988). Архивировано 5 июня 2012 года. ↑ Newquist, HP. The Brain Makers, Second Edition. — New York, NY : The Relayer Group, 2018. — P. 491. ↑ https://www.theguardian.com/obituaries/story/0,,2122424,00.html obituary of Donald Michie in The Guardian Архивировано 27 января 2008 года. ↑ Yarden Katz, «Noam Chomsky on Where Artificial Intelligence Went Wrong» , The Atlantic, 1 November 2012 Архивировано 3 ноября 2012 года. ↑ Noam Chomsky, «Pinker/Chomsky Q&A from MIT150 Panel» Архивировано 17 мая 2013 года. ↑ Peter Norvig, «On Chomsky and the Two Cultures of Statistical Learning» Архивировано 27 мая 2011 года. Литература [ править | править код ] Crevier, Daniel. AI: The Tumultuous Search Artificial Intelligence (англ.) . — New York, NY: BasicBooks, 1993. — ISBN 0-465-02997-3 . Hendler, James [англ.] . Where Are All the Intelligent Agents? (англ.) // IEEE Intelligent Systems [англ.] : journal. — 2007. — Vol. 22 , no. 3 . — P. 2—3 . — doi : 10.1109/MIS.2007.62 . Howe, J. Artificial Intelligence at Edinburgh University : a Perspective (неопр.) (ноябрь 1994). Дата обращения: 30 августа 2007. Архивировано 17 августа 2007 года. Андреас Каплан ; Haenlein, Michael. Siri, Siri in my Hand, who's the Fairest in the Land? On the Interpretations, Illustrations and Implications of Artificial Intelligence (англ.) : journal. — Business Horizons 62(1), 2018. Архивировано 21 ноября 2018 года. Kurzweil, Ray [англ.] . The Singularity is Near (неопр.) . — Viking Press, 2005. Lighthill, Professor Sir James [англ.] . Artificial Intelligence: a paper symposium (итал.) . — Science Research Council, 1973. Minsky, Marvin [англ.] ; Papert, Seymour. Perceptrons: An Introduction to Computational Geometry (англ.) : journal. — The MIT Press, 1969. McCorduck, Pamela. Machines Who Think (2nd ed.) (англ.) . — Natick, MA: A. K. Peters, Ltd., 2004. — ISBN 1-56881-205-1 . NRC [англ.] . Developments in Artificial Intelligence // Funding a Revolution: Government Support for Computing Research (англ.) . — National Academy Press [англ.] , 1999. Newquist, HP [англ.] . The Brain Makers: Genius, Ego, and Greed In The Search For Machines That Think (англ.) . — Macmillan/SAMS, 1994. — ISBN 978-0-9885937-1-8 . Russell, Stuart J.; Norvig, Peter. Artificial Intelligence: A Modern Approach (2nd ed.) (англ.) . — Upper Saddle River, New Jersey: Prentice Hall, 2003. — ISBN 0-13-790395-2 . Искусственный интеллект История Вычислительные машины и разум Зима искусственного интеллекта Бум искусственного интеллекта Джорджтаунский эксперимент Дартмутский семинар Отчёт Лайтхилла Регламент ЕС Гонка вооружений в области искусственного интеллекта Холодная война за искусственный интеллект Философия Тест Тьюринга Китайская комната Сильный и слабый искусственные интеллекты Дружественный искусственный интеллект Этика искусственного интеллекта Проблема контроля Направления Агентный подход Адаптивное управление Генеративный ИИ Инженерия знаний Модель жизнеспособной системы Машинное обучение Нейронная сеть Нечёткая логика Обработка естественного языка Персональный искусственный интеллект Распознавание образов Роевой интеллект Символический ИИ Эволюционные алгоритмы Экспертная система Применение Голосовое управление Задача классификации Классификация документов Кластеризация документов Кластерный анализ Локальный поиск Машинный перевод Оптическое распознавание символов Распознавание речи Распознавание рукописного ввода Игровой ИИ Исследователи Чарлз Бэббидж Владимир Вапник Джозеф Вейценбаум Норберт Винер Виктор Глушков Владимир Городецкий Рэймонд Курцвейл Ян Лекун Алексей Ляпунов Джон Маккарти Марвин Мински Аллен Ньюэлл Сеймур Пейперт Джуда Перл Гермоген Поспелов Дмитрий Поспелов Фрэнк Розенблатт Герберт Саймон Алан Тьюринг Патрик Уинстон Виктор Финн Сергей Фомин Демис Хассабис Джеффри Хинтон Ноам Хомский Клод Шеннон Эндрю Ын Элиезер Юдковский Источник — https://ru.wikipedia.org/w/index.php?title=Зима_искусственного_интеллекта&oldid=143528394 Категория : История искусственного интеллекта Скрытые категории: Википедия:Cite web (не указан язык) Википедия:Обслуживание CS1 (множественные имена: authors list) Википедия:Статьи с нерабочими ссылками Страницы, использующие волшебные ссылки ISBN Википедия:Cite web (статьи с неверным параметром) Навигация Поиск