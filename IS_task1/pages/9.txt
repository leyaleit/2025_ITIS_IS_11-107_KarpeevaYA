Машинное обучение — Википедия Машинное обучение Материал из Википедии — свободной энциклопедии Перейти к навигации Перейти к поиску Машинное обучение ( англ. machine learning , ML) — класс методов искусственного интеллекта , характерной чертой которых является не прямое решение задачи, а обучение за счёт применения решений множества сходных задач. Для построения таких методов используются средства математической статистики , численных методов , математического анализа , методов оптимизации , теории вероятностей , теории графов , различные техники работы с данными в цифровой форме . Различают два типа обучения: Обучение по прецедентам , или индуктивное обучение , основано на выявлении эмпирических закономерностей в данных . Дедуктивное обучение предполагает формализацию знаний экспертов и их перенос в компьютер в виде базы знаний . Дедуктивное обучение принято относить к области экспертных систем , поэтому термины машинное обучение и обучение по прецедентам можно считать синонимами. Многие методы индуктивного обучения разрабатывались как альтернатива классическим статистическим подходам. Многие методы тесно связаны с извлечением информации ( англ. information extraction , information retrieval ), интеллектуальным анализом данных ( data mining ). Содержание 1 Общая постановка задачи обучения по прецедентам 2 Способы машинного обучения 3 Классические задачи, решаемые с помощью машинного обучения 4 Типы входных данных при обучении 5 Типы функционалов качества 6 Практические сферы применения 7 См. также 8 Примечания 8.1 Комментарии 8.2 Сноски 9 Литература 10 Ссылки Общая постановка задачи обучения по прецедентам [ править | править код ] Имеется множество объектов (ситуаций) и множество возможных ответов (откликов, реакций). Существует некоторая зависимость между ответами и объектами, но она неизвестна. Известна только конечная совокупность прецедентов — пар «объект, ответ», называемая обучающей выборкой . На основе этих данных требуется восстановить неявную зависимость, то есть построить алгоритм, способный для любого возможного входного объекта выдать достаточно точный классифицирующий ответ. Эта зависимость не обязательно выражается аналитически, и здесь нейросети реализуют принцип эмпирически формируемого решения. Важной особенностью при этом является способность обучаемой системы к обобщению, то есть к адекватному отклику на данные, выходящие за пределы имеющейся обучающей выборки. Для измерения точности ответов вводится оценочный функционал качества . Данная постановка является обобщением классических задач аппроксимации функций. В классических задачах аппроксимации объектами являются действительные числа или векторы. В реальных прикладных задачах входные данные об объектах могут быть неполными, неточными, нечисловыми, разнородными. Эти особенности приводят к большому разнообразию методов машинного обучения. Способы машинного обучения [ править | править код ] Раздел машинного обучения, с одной стороны, образовался в результате разделения науки о нейросетях на методы обучения сетей и виды топологий их архитектуры, с другой стороны — вобрал в себя методы математической статистики [ a ] . Указанные ниже способы машинного обучения основаны на применении нейросетей, хотя существуют и другие методы, основанные на обучающей выборке — например, дискриминантный анализ, оперирующий обобщённой дисперсией и ковариацией наблюдаемой статистики, или байесовские классификаторы. Базовые виды нейросетей, такие как перцептрон и многослойный перцептрон (а также их модификации), могут обучаться как с учителем, так и без учителя, с подкреплением и самоорганизацией. Но некоторые нейросети и большинство статистических методов можно отнести только к одному из способов обучения. Поэтому, если нужно классифицировать методы машинного обучения в зависимости от способа обучения, то будет некорректным относить нейросети к определенному виду, правильнее было бы типизировать алгоритмы обучения нейронных сетей. Обучение с учителем — для каждого прецедента задаётся пара «ситуация, требуемое решение»: Искусственная нейронная сеть Глубокое обучение Метод коррекции ошибки Метод обратного распространения ошибки Метод опорных векторов Обучение без учителя — когда требуется сгруппировать объекты в кластеры , используя данные о попарном сходстве объектов, и/или понизить размерность данных: Альфа-система подкрепления Гамма-система подкрепления Метод ближайших соседей Обучение с подкреплением — для каждого прецедента имеется пара «ситуация, принятое решение»: Генетический алгоритм . Активное обучение — отличается тем, что обучаемый алгоритм имеет возможность самостоятельно назначать следующую исследуемую ситуацию, на которой станет известен верный ответ: Обучение с частичным привлечением учителя ( англ. semi-supervised learning ) — для части прецедентов задается пара «ситуация, требуемое решение», а для части — только «ситуация» Трансдуктивное обучение — обучение с частичным привлечением учителя, когда прогноз предполагается делать только для прецедентов из тестовой выборки Многозадачное обучение ( англ. multi-task learning ) — одновременное обучение группе взаимосвязанных задач, для каждой из которых задаются свои пары «ситуация, требуемое решение» Многовариантное обучение ( англ. multiple-instance learning ) — обучение, когда прецеденты могут быть объединены в группы, в каждой из которых для всех прецедентов имеется «ситуация», но только для одного из них (причем, неизвестно какого) имеется пара «ситуация, требуемое решение» Бустинг ( англ. boosting — улучшение) — это процедура последовательного построения композиции алгоритмов машинного обучения, когда каждый следующий алгоритм стремится компенсировать недостатки композиции всех предыдущих алгоритмов. Байесовская сеть Классические задачи, решаемые с помощью машинного обучения [ править | править код ] Классификация , как правило, выполняется с помощью обучения с учителем на этапе собственно обучения. Кластеризация , как правило, выполняется с помощью обучения без учителя Регрессия , как правило, выполняется с помощью обучения с учителем на этапе тестирования, является частным случаем задач прогнозирования . Понижение размерности данных и их визуализация выполняется с помощью обучения без учителя Восстановление плотности распределения вероятности по набору данных Одноклассовая классификация и выявление новизны Построение ранговых зависимостей Обнаружение аномалий Типы входных данных при обучении [ править | править код ] Признаковое описание объектов или матрица объекты-признаки — наиболее распространённый случай. Каждый объект описывается набором признаков. Матрица расстояний между объектами. Каждый объект описывается расстояниями до всех остальных объектов обучающей выборки, чаще всего отношениями попарного сходства. Временной ряд или сигнал . Последовательность измерений во времени, которое может представляться числом, вектором, а в общем случае — признаковым описанием в данный момент времени. Изображение или видеоряд . Обычный текст с помощью обработки естественного языка . Типы функционалов качества [ править | править код ] При обучении с учителем — функционал качества может определяться как средняя ошибка ответов. Предполагается, что искомый алгоритм должен его минимизировать. Для предотвращения переобучения в минимизируемый функционал качества часто в явном или неявном виде добавляют регуляризатор. При обучении без учителя — функционалы качества могут определяться по-разному, например, как отношение средних межкластерных и внутрикластерных расстояний. При обучении с подкреплением — функционалы качества определяются физической средой, показывающей качество приспособления агента. Практические сферы применения [ править | править код ] Целью машинного обучения является частичная или полная автоматизация решения сложных профессиональных задач в самых разных областях человеческой деятельности. Машинное обучение имеет широкий спектр приложений [ источник не указан 4184 дня ] : Распознавание речи Распознавание жестов Распознавание рукописного ввода Распознавание образов Техническая диагностика Медицинская диагностика Прогнозирование временных рядов Биоинформатика Обнаружение мошенничества Обнаружение спама Категоризация документов Биржевой технический анализ Финансовый надзор (см. также Финансовые преступления ) Кредитный скоринг Прогнозирование ухода клиентов Хемоинформатика Обучение ранжированию в информационном поиске Сфера применений машинного обучения постоянно расширяется. Повсеместная информатизация приводит к накоплению огромных объёмов данных в науке, производстве, бизнесе, транспорте, здравоохранении. Возникающие при этом задачи прогнозирования, управления и принятия решений часто сводятся к обучению по прецедентам. Раньше, когда таких данных не было, эти задачи либо вообще не ставились, либо решались совершенно другими методами. См. также [ править | править код ] Глубокое обучение Квантовое машинное обучение Искусственный интеллект Примечания [ править | править код ] Комментарии [ править | править код ] ↑ По мнению известного специалиста по машинному обучению Ян Лекуна , машинное обучение есть воспроизведение мышления на основе искусственных нейронных сетей [ 1 ] Сноски [ править | править код ] ↑ Лекун, 2021 , с. 78. Литература [ править | править код ] Айвазян С. А. , Енюков И. С., Мешалкин Л. Д. Прикладная статистика: основы моделирования и первичная обработка данных. — М.: Финансы и статистика, 1983. Айвазян С. А., Енюков И. С., Мешалкин Л. Д. Прикладная статистика: исследование зависимостей. — М.: Финансы и статистика, 1985. Айвазян С. А., Бухштабер В. М. , Енюков И. С., Мешалкин Л. Д. Прикладная статистика: классификация и снижение размерности. — М.: Финансы и статистика, 1989. Вапник В. Н. Восстановление зависимостей по эмпирическим данным. — М.: Наука , 1979. Журавлёв Ю. И ., Рязанов В. В., Сенько О. В. «Распознавание». Математические методы. Программная система. Практические применения. — М.: Фазис, 2006. ISBN 5-7036-0108-8 . Загоруйко Н. Г. Прикладные методы анализа данных и знаний. — Новосибирск: ИМ СО РАН, 1999. ISBN 5-86134-060-9 . Флах П. Машинное обучение. — М. : ДМК Пресс, 2015. — 400 с. — ISBN 978-5-97060-273-7 . Шлезингер М., Главач В. Десять лекций по статистическому и структурному распознаванию. — Киев: Наукова думка , 2004. ISBN 966-00-0341-2 . Hastie, T., Tibshirani R., Friedman J. The Elements of Statistical Learning: Data Mining, Inference, and Prediction . — 2nd ed. — Springer-Verlag, 2009. — 746 p. — ISBN 978-0-387-84857-0 . . Mitchell T. Machine Learning. — McGraw-Hill Science/Engineering/Math, 1997. ISBN 0-07-042807-7 . Ryszard S. Michalski, Jaime G. Carbonell, Tom M. Mitchell (1983), Machine Learning: An Artificial Intelligence Approach , Tioga Publishing Company, ISBN 0-935382-05-4 ( Machine Learning: An Artificial Intelligence Approach в « Книгах Google »). Vapnik V. N. Statistical learning theory. — N.Y.: John Wiley & Sons, Inc., 1998. [1] Bernhard Schölkopf , Alexander J. Smola Learning with Kernels. Support Vector Machines, Regularization, Optimization, and Beyond. — MIT Press , Cambridge, MA, 2002 ISBN 978-0-262-19475-4 [2] I. H. Witten , E. Frank Data Mining: Practical Machine Learning Tools and Techniques (Second Edition). — Morgan Kaufmann, 2005 ISBN 0-12-088407-0 [3] Liang Wang, Li Cheng, Guoying Zhao. Machine Learning for Human Motion Analysis. — IGI Global, 2009. — 318 p. — ISBN 978-1-60566-900-7 . Ян Лекун . Как учится машина. Революция в области нейронных сетей и глубокого обучения. (Библиотека Сбера: Искусственный интеллект). — М. : Альпина нон-фикшн, 2021. — 348 с. — ISBN 978-5-907394-29-2 . Ссылки [ править | править код ] Weka: Data Mining Software in Java www.MachineLearning.ru — профессиональный вики-ресурс, посвященный машинному обучению и интеллектуальному анализу данных ММРО — Математические методы распознавания образов Константин Воронцов . Курс лекций Математические методы обучения по прецедентам , МФТИ , 2004—2008 Константин Воронцов . Курс «машинное обучение» школы анализа данных компании Яндекс . Игорь Кураленок . Курс «машинное обучение» Лекториум. Роман Шамин . Курс «Машинное обучение и искусственный интеллект в математике и приложениях» . НОЦ Математического института им. В. А. Стеклова РАН Ссылки на внешние ресурсы Словари и энциклопедии Большая китайская Большая китайская Большая китайская Большая норвежская Britannica (онлайн) De Agostini Treccani В библиографических каталогах GND : 4193754-5 J9U : 987007541156405171 LCCN : sh85079324 NDL : 001210569 NKC : ph126143 Искусственный интеллект История Вычислительные машины и разум Зима искусственного интеллекта Бум искусственного интеллекта Джорджтаунский эксперимент Дартмутский семинар Отчёт Лайтхилла Регламент ЕС Гонка вооружений в области искусственного интеллекта Холодная война за искусственный интеллект Философия Тест Тьюринга Китайская комната Сильный и слабый искусственные интеллекты Дружественный искусственный интеллект Этика искусственного интеллекта Проблема контроля Направления Агентный подход Адаптивное управление Генеративный ИИ Инженерия знаний Модель жизнеспособной системы Машинное обучение Нейронная сеть Нечёткая логика Обработка естественного языка Персональный искусственный интеллект Распознавание образов Роевой интеллект Символический ИИ Эволюционные алгоритмы Экспертная система Применение Голосовое управление Задача классификации Классификация документов Кластеризация документов Кластерный анализ Локальный поиск Машинный перевод Оптическое распознавание символов Распознавание речи Распознавание рукописного ввода Игровой ИИ Исследователи Чарлз Бэббидж Владимир Вапник Джозеф Вейценбаум Норберт Винер Виктор Глушков Владимир Городецкий Рэймонд Курцвейл Ян Лекун Алексей Ляпунов Джон Маккарти Марвин Мински Аллен Ньюэлл Сеймур Пейперт Джуда Перл Гермоген Поспелов Дмитрий Поспелов Фрэнк Розенблатт Герберт Саймон Алан Тьюринг Патрик Уинстон Виктор Финн Сергей Фомин Демис Хассабис Джеффри Хинтон Ноам Хомский Клод Шеннон Эндрю Ын Элиезер Юдковский Машинное обучение и data mining Задачи Задача классификации Обучение без учителя Обучение с частичным привлечением учителя Регрессионный анализ AutoML Ассоциативные правила Выделение признаков Обучение признакам Обучение ранжированию Грамматический вывод Онлайновое обучение Обучение с учителем Метод k ближайших соседей Наивный байесовский классификатор Дерево решений Метод опорных векторов Линейная регрессия Логистическая регрессия Перцептрон Ансамблевое обучение Бэггинг Бустинг Метод случайного леса Метод релевантных векторов Кластерный анализ Метод k-средних Метод нечёткой кластеризации Иерархическая кластеризация EM-алгоритм BIRCH CURE DBSCAN OPTICS Mean-shift Снижение размерности Факторный анализ Метод главных компонент CCA ICA LDA Неотрицательное матричное разложение t-SNE Структурное прогнозирование Графовая вероятностная модель Байесовская сеть Скрытая марковская модель CRF Выявление аномалий Метод k ближайших соседей Локальный уровень выброса Графовые вероятностные модели Байесовская сеть Марковская сеть Скрытая марковская модель Нейронные сети Ограниченная машина Больцмана Самоорганизующаяся карта Функция активации Сигмоида Softmax Радиально-базисная функция Метод обратного распространения ошибки Глубокое обучение Многослойный перцептрон Рекуррентная нейронная сеть Долгая краткосрочная память Управляемый рекуррентный блок Свёрточная нейронная сеть U-Net Автокодировщик Обучение с подкреплением Марковский процесс Уравнение Беллмана Жадный алгоритм Q-обучение SARSA Temporal difference (TD) Теория Размерность Вапника — Червоненкиса Дилемма смещения–дисперсии Теория вычислительного обучения Минимизация эмпирического риска Оккамово обучение PAC learning Статистическая теория обучения Журналы и конференции NeurIPS ICML ML JMLR ArXiv:cs.LG Для улучшения этой статьи желательно : Проставить сноски , внести более точные указания на источники. Переработать оформление в соответствии с правилами написания статей . После исправления проблемы исключите её из списка. Удалите шаблон, если устранены все недостатки. Источник — https://ru.wikipedia.org/w/index.php?title=Машинное_обучение&oldid=143179382 Категория : Машинное обучение Скрытые категории: Википедия:Статьи без источников (тип: специальность) Википедия:Нет источников с октября 2013 Википедия:Статьи с утверждениями без источников более 14 дней Википедия:Статьи без сносок Википедия:Статьи с неэнциклопедическим содержанием Википедия:Статьи с шаблонами недостатков по алфавиту Страницы, использующие волшебные ссылки ISBN Навигация Поиск