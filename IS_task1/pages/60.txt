Тест Тьюринга — Википедия Тест Тьюринга Материал из Википедии — свободной энциклопедии Текущая версия страницы пока не проверялась опытными участниками и может значительно отличаться от версии, проверенной 15 марта 2025 года ; проверки требуют 3 правки . Перейти к навигации Перейти к поиску Эта статья нуждается в переработке . Пожалуйста, уточните проблему в статье с помощью более узкого шаблона . Пожалуйста, улучшите статью в соответствии с правилами написания статей . ( 30 октября 2024 ) Информация в этой статье или некоторых её разделах устарела . Вы можете помочь проекту, обновив её и убрав после этого данный шаблон. ( 16 июня 2024 ) Стандартная интерпретация теста Тьюринга Тест Тью́ринга — эмпирический тест, идея которого была предложена Аланом Тьюрингом в статье « Вычислительные машины и разум », опубликованной в 1950 году в философском журнале Mind . Тьюринг задался целью определить, может ли машина мыслить . Стандартная интерпретация этого теста звучит следующим образом: « Человек взаимодействует с одним компьютером и одним человеком. На основании ответов на вопросы он должен определить, с кем он разговаривает: с человеком или компьютерной программой. Задача компьютерной программы — ввести человека в заблуждение, заставив сделать неверный выбор ». Все участники теста не видят друг друга. Если судья не может сказать определённо, кто из собеседников является человеком, то считается, что машина прошла тест. Чтобы протестировать именно интеллект машины, а не её возможность распознавать устную речь, беседа ведётся в режиме «только текст», например, с помощью клавиатуры и экрана (компьютера-посредника). Переписка должна производиться через контролируемые промежутки времени, чтобы судья не мог делать заключения, исходя из скорости ответов. Во времена Тьюринга компьютеры реагировали медленнее человека. Сейчас это правило тоже необходимо, потому что они реагируют гораздо быстрее, чем человек. Содержание 1 История 1.1 Философские предпосылки 1.2 Алан Тьюринг 1.3 Элиза и PARRY 1.4 Китайская комната 1.5 Коллоквиум Тьюринга 1.6 Премия Лёбнера 1.7 Коллоквиум по разговорным системам, 2005 1.8 Симпозиум общества AISB по тесту Тьюринга, 2008 1.9 Год Алана Тьюринга и Тьюринг-100 в 2012 1.10 Тест Тьюринга на русском языке, 2015 1.11 GPT-4 2 Варианты теста Тьюринга 2.1 Имитационная игра 2.2 Стандартная интерпретация 2.3 Имитационная игра в сравнении со стандартным тестом Тьюринга 2.4 Должен ли судья знать о компьютере? 3 Достоинства теста 3.1 Ширина темы 3.2 Уступчивость и простота 4 Недостатки теста 4.1 Человеческий разум и разум в целом 4.2 Непрактичность 4.3 Реальный интеллект и имитируемый интеллект 5 Предсказания 6 Вариации теста Тьюринга 6.1 Обратный тест Тьюринга и CAPTCHA 6.2 Тест Тьюринга со специалистом 6.3 Тест бессмертия 6.4 Минимальный интеллектуальный Signal-тест (MIST) 6.5 Мета-тест Тьюринга 6.6 Премия Хаттера 6.7 Другие тесты интеллекта 6.8 Тест BotPrize 6.9 Женя Густман 6.10 Схема Винограда 6.11 Тесты для учеников школ 6.12 Задания по сборке 6.13 I-Athlon 7 В искусстве 8 См. также 9 Примечания 10 Литература 11 Ссылки История [ править | править код ] Философские предпосылки [ править | править код ] Хотя исследования в области искусственного интеллекта начались в 1956 году , их философские корни уходят глубоко в прошлое . Вопрос, сможет ли машина думать, имеет долгую историю. Он тесно связан с различиями между дуалистическим и материалистическим взглядами.
С точки зрения дуализма, мысль не является материальной (или, по крайней мере, не имеет материальных свойств), и поэтому разум нельзя объяснить только с помощью физических понятий.
С другой стороны, материализм гласит, что разум можно объяснить физически, таким образом, оставляя возможность существования разумов, созданных искусственно. В 1936 году философ Альфред Айер рассмотрел обычный для философии вопрос касательно других разумов: как узнать, что другие люди имеют тот же сознательный опыт, что и мы? В своей книге «Язык, истина и логика» Айер предложил алгоритм распознавания осознающего человека и неосознающей машины: «Единственным основанием, на котором я могу утверждать, что объект, который кажется разумным, на самом деле не разумное существо, а просто глупая машина, является то, что он не может пройти один из эмпирических тестов, согласно которым определяется наличие или отсутствие сознания». Это высказывание очень похоже на тест Тьюринга, однако точно неизвестно, была ли известна Тьюрингу популярная философская классика Айера. Несмотря на то что прошло больше 50 лет, тест Тьюринга не потерял своей значимости. Но в настоящее время исследователи искусственного интеллекта практически не занимаются решением задачи прохождения теста Тьюринга, считая, что гораздо важнее изучить основополагающие принципы интеллекта, чем продублировать одного из носителей естественного интеллекта. В частности, проблему «искусственного полёта» удалось успешно решить лишь после того, как братья Райт и другие исследователи перестали имитировать птиц и приступили к изучению аэродинамики. В научных и технических работах по воздухоплаванию цель этой области знаний не определяется как «создание машин, которые в своем полёте настолько напоминают голубей, что даже могут обмануть настоящих птиц». [ 1 ] Алан Тьюринг [ править | править код ] К 1956 году британские учёные уже на протяжении 10 лет исследовали «машинный интеллект». Этот вопрос был обычным предметом для обсуждения среди членов «Ratio Club» — неформальной группы британских кибернетиков и исследователей в области электроники, в которой состоял и Алан Тьюринг, в честь которого был назван тест. Тьюринг в особенности занимался проблемой машинного интеллекта, по меньшей мере с 1941 года. Одно из самых первых его упоминаний о «компьютерном интеллекте» было сделано в 1947 году. В докладе «Интеллектуальные машины» Тьюринг исследовал вопрос, может ли машина обнаруживать разумное поведение, и в рамках этого исследования предложил то, что может считаться предтечей его дальнейших исследований: «Нетрудно разработать машину, которая будет неплохо играть в шахматы. Теперь возьмем трёх человек — субъектов эксперимента. А, В и С. Пусть А и С неважно играют в шахматы, а В — оператор машины. […] Используются две комнаты, а также некоторый механизм для передачи сообщений о ходах. Участник С играет или с А, или с машиной. Участник С может затрудниться ответить, с кем он играет». Таким образом, к моменту публикации в 1950 году статьи «Вычислительные машины и разум» Тьюринг уже на протяжении многих лет рассматривал возможность существования искусственного интеллекта. Тем не менее данная статья стала первой статьёй Тьюринга, в которой рассматривалось исключительно это понятие. Тьюринг начинает свою статью утверждением: «Я предлагаю рассмотреть вопрос „Могут ли машины думать?“». Он подчёркивает, что традиционный подход к этому вопросу состоит в том, чтобы сначала определить понятия «машина» и «интеллект». Тьюринг, однако, выбрал другой путь; вместо этого он заменил исходный вопрос другим, «который тесно связан с исходным и формулируется относительно недвусмысленно». По существу, он предлагает заменить вопрос «Думают ли машины?» вопросом «Могут ли машины делать то, что можем делать мы (как мыслящие создания)?». Преимуществом нового вопроса, как утверждает Тьюринг, является то, что он проводит «чёткую границу между физическими и интеллектуальными возможностями человека». Чтобы продемонстрировать этот подход, Тьюринг предлагает тест, придуманный по аналогии с игрой для вечеринок «Imitation game» — имитационная игра. В этой игре мужчина и женщина направляются в разные комнаты, а гости пытаются различить их, задавая им серию письменных вопросов и читая напечатанные на машинке ответы на них. По правилам игры и мужчина, и женщина пытаются убедить гостей, что всё наоборот. Тьюринг предлагает переделать игру следующим образом: «Теперь зададим вопрос, что случится, если в этой игре роль А будет исполнять машина? Будет ли задающий вопросы ошибаться так же часто, как если бы он играл с мужчиной и женщиной? Эти вопросы заменяют собой исходный „Может ли машина думать?“». В том же докладе Тьюринг позднее предлагает «эквивалентную» альтернативную формулировку, включающую судью, который беседует только с компьютером и человеком. Наряду с тем, что ни одна из этих формулировок точно не соответствует той версии теста Тьюринга, которая наиболее известна сегодня, в 1952 году учёный предложил третью. В этой версии теста, которую Тьюринг обсудил в эфире радио Би-Би-Си, жюри задаёт вопросы компьютеру, а роль компьютера состоит в том, чтобы заставить значительную часть членов жюри поверить, что он на самом деле человек. В статье Тьюринга учтены 9 предполагаемых вопросов, которые включают все основные возражения против искусственного интеллекта, поднятые после того, как статья была впервые опубликована. Элиза и PARRY [ править | править код ] Блей Витби указывает на четыре основные поворотные точки в истории теста Тьюринга — публикация статьи «Вычислительные машины и разум» в 1950 году, сообщение о создании Джозефом Вейценбаумом программы Элиза (ELIZA) в 1966, создание Кеннетом Колби программы PARRY , которая была впервые описана в 1972 году, и Коллоквиум Тьюринга в 1990. Принцип работы Элизы заключается в исследовании введённых пользователем комментариев на наличие ключевых слов. Если найдено ключевое слово, то применяется правило, по которому комментарий пользователя преобразуется и возвращается предложение-результат. Если же ключевое слово не найдено, Элиза либо возвращает пользователю общий ответ, либо повторяет один из предыдущих комментариев. Вдобавок Уайзенбаум запрограммировал Элизу на имитацию поведения психотерапевта, работающего по клиент-центрированной методике. Это позволяет Элизе «притвориться, что она не знает почти ничего о реальном мире». Применяя эти способы, программа Уайзенбаума могла вводить в заблуждение некоторых людей, которые думали, что они разговаривают с реально существующим человеком, а некоторых было «очень трудно убедить, что Элиза […] не человек». На этом основании некоторые утверждают, что Элиза — одна из программ (возможно первая), которые смогли пройти тест Тьюринга. Однако это утверждение очень спорно, так как людей, «задающих вопросы», инструктировали так, чтобы они думали, что с ними будет разговаривать настоящий психотерапевт, и не подозревали о том, что они могут разговаривать с компьютером. Работа Колби — PARRY — была описана как «Элиза с мнениями»: программа пыталась моделировать поведение параноидального шизофреника, используя схожий (если не более продвинутый) с Элизой подход, применённый Уайзенбаумом. Для того чтобы проверить программу, PARRY тестировали в начале 70-х, используя модификацию теста Тьюринга. Команда опытных психиатров анализировала группу, составленную из настоящих пациентов и компьютеров под управлением PARRY, используя телетайп. Другой команде из 33 психиатров позже показали стенограммы бесед. Затем обе команды попросили определить, кто из «пациентов» — человек, а кто — компьютерная программа. Психиатры лишь в 48 % случаев смогли вынести верное решение. Эта цифра согласуется с вероятностью случайного выбора. Эти эксперименты не являлись тестами Тьюринга в полном смысле, так как для вынесения решения данный тест требует, чтобы вопросы можно было задавать в интерактивном режиме, вместо чтения стенограммы прошедшей беседы. Почти все разработанные программы и близко не подошли к прохождению теста. Хотя такие программы, как Элиза, иногда заставляли людей верить, что они говорят с человеком, как, например, в неформальном эксперименте, названном AOLiza , но эти случаи нельзя считать корректным прохождением теста Тьюринга по целому ряду причин: Человек в таких беседах не имел никаких оснований считать, что он говорит с программой, в то время как в настоящем тесте Тьюринга человек активно пытается определить, с кем он беседует. Документированные случаи обычно относятся к таким чатам , как IRC , где многие беседы отрывочны и бессмысленны. Многие пользователи Интернета используют английский как второй или третий язык, так что бессмысленный ответ программы легко может быть списан на языковой барьер. Многие просто ничего не знают об Элизе и ей подобных программах и поэтому не сочтут собеседника программой даже в случае совершенно нечеловеческих ошибок, которые эти программы допускают. Другие примеры Машина может избежать лишних вопросов, например, притворившись параноиком, подростком или иностранцем с недостаточным знанием местного языка. Победитель одного из последних конкурсов, организованных по принципу теста Тьюринга, — бот по имени Женя Густман — сумел объединить все три приёма, притворяясь тринадцатилетним мальчишкой из Одессы [ 2 ] . Китайская комната [ править | править код ] Основная статья: Китайская комната В 1980 году в статье «Разум, мозг и программы» Джон Сёрль выдвинул аргумент против теста Тьюринга, известный как мысленный эксперимент « Китайская комната ». Сёрль настаивал, что программы (такие как Элиза ) смогли пройти тест Тьюринга, просто манипулируя символами, значения которых они не понимали. А без понимания их нельзя считать «разумными» в том же смысле, что и людей. «Таким образом, — заключает Сёрль, — тест Тьюринга не является доказательством того, что машина может думать, а это противоречит изначальному предположению Тьюринга». Такие аргументы, как предложенный Сёрлем, а также другие, основанные на философии разума, породили намного более бурные дискуссии о природе разума, возможности существования разумных машин и значимости теста Тьюринга, продолжавшиеся в течение 80-х и 90-х годов. Коллоквиум Тьюринга [ править | править код ] В 1990 году состоялась сороковая годовщина публикации статьи Тьюринга «Вычислительные машины и разум», что возобновило интерес к тесту. В этом году произошли два важных события. Одно из них — коллоквиум Тьюринга, который проходил в апреле в Университете Сассекса. В его рамках встретились академики и исследователи из разнообразных областей науки, чтобы обсудить тест Тьюринга с позиций его прошлого, настоящего и будущего. Вторым событием стало учреждение ежегодного соревнования на получение премии Лёбнера. Премия Лёбнера [ править | править код ] Основная статья: Премия Лёбнера Ежегодный конкурс «AI Loebner» на получение премии Лёбнера является платформой для практического проведения тестов Тьюринга. Первый конкурс прошёл в ноябре 1991 года . Приз гарантирован Хью Лёбнером (Hugh Loebner). Кембриджский центр исследований поведения, расположенный в Массачусетсе (США), предоставлял призы до 2003 года включительно. По словам Лёбнера, соревнование было организовано с целью продвижения вперёд в области исследований, связанных с искусственным интеллектом, отчасти потому, что «никто не предпринял мер, чтобы это осуществить». Серебряная (текстовая) и золотая (аудио- и зрительная) медали никогда ещё не вручались. Тем не менее ежегодно из всех представленных на конкурс компьютерных систем судьи награждают бронзовой медалью ту, которая, по их мнению, продемонстрирует «наиболее человеческое» поведение в разговоре. Не так давно программа «Искусственное лингвистическое интернет-компьютерное существо» (Artificial Linguistic Internet Computer Entity — A.L.I.C.E. ) трижды завоевала бронзовую медаль (в 2000, 2001 и 2004). Способная к обучению программа Jabberwacky [ 3 ] побеждала в 2005 и 2006. Её создатели предложили персонализированную версию: возможность пройти имитационный тест, пытаясь более точно сымитировать человека, с которым машина тесно пообщалась перед тестом. Конкурс проверяет способность разговаривать; победителями становятся обычно чат-боты или « Искусственные разговорные существа » (Artificial Conversational Entities (ACE)s). Правилами первых конкурсов предусматривалось ограничение. Согласно этому ограничению каждая беседа с программой или скрытым человеком могла быть только на одну тему. Начиная с конкурса 1995 года, это правило отменено. Продолжительность разговора между судьёй и участником была различной в разные годы. В 2003 году, когда конкурс проходил в Университете Суррея, каждый судья мог разговаривать с каждым участником (машиной или человеком) ровно 5 минут. С 2004 по 2007 это время составляло уже более 20 минут. В 2008 максимальное время разговора составляло 5 минут на пару, потому что организатор Кевин Ворвик (Kevin Warwick) и координатор Хьюма Ша (Huma Shah) полагали, что ACE не имели технических возможностей поддерживать более продолжительную беседу. Победитель 2008 года, Elbot [ 4 ] , не притворялся человеком, но всё-таки сумел обмануть трёх судей. В конкурсе, проведённом в 2010 году, время при общении между системой и исследователем было увеличено до 25 минут по требованию спонсора (программы продвинулись вперёд в способности имитировать человека, и только при длительной беседе появляются нюансы, позволяющие вычислять собеседника). Конкурс, проведённый 15 мая 2012 года, состоялся впервые в мире с прямой трансляцией беседы, что только подогревает интерес к данному конкурсу. Появление конкурса на получение премии Лёбнера привело к возобновлению дискуссий о целесообразности теста Тьюринга, о значении его прохождения. В статье «Искусственная тупость» газеты The Economist отмечается, что первая программа — победитель конкурса смогла выиграть отчасти потому, что она «имитировала человеческие опечатки». (Тьюринг предложил, чтобы программы добавляли ошибки в вывод, чтобы быть более хорошими «игроками»). Существовало мнение, что попытки пройти тест Тьюринга просто препятствуют более плодотворным исследованиям. Во время первых конкурсов была выявлена вторая проблема: участие недостаточно компетентных судей, которые поддавались умело организованным манипуляциям, а не тому, что можно считать интеллектом. Тем не менее с 2004 года в качестве собеседников в конкурсе принимают участие философы, компьютерные специалисты и журналисты. Судейство на конкурсе очень строгое. Эксперты заранее готовятся к турниру и подбирают весьма заковыристые вопросы, чтобы понять, с кем же они общаются. Их разговор с программами напоминает допрос следователя. Судьи любят, например, повторять некоторые вопросы через определённое время, так как слабые боты не умеют следить за историей диалога и их можно поймать на однообразных ответах [ 5 ] . Коллоквиум по разговорным системам, 2005 [ править | править код ] В ноябре 2005 года в Университете Суррея проходила однодневная встреча разработчиков ACE, которую посетили победители практических тестов Тьюринга, проходивших в рамках конкурса на получение премии Лёбнера: Робби Гарнер (Robby Garner), Ричард Уоллес (Richard Wallace), Ролл Карпентер (Rollo Carpenter). В числе приглашённых докладчиков были Дэвид Хэмилл (David Hamill), Хью Лёбнер и Хьюма Ша. Симпозиум общества AISB по тесту Тьюринга, 2008 [ править | править код ] В 2008 году наряду с проведением очередного конкурса на получение премии Лёбнера, проходившего в Университете Рединга (University of Reading), Общество изучения искусственного интеллекта и моделирования поведения (The Society for the Study of Artificial Intelligence and Simulation of Behavior — AISB) провело однодневный симпозиум, на котором обсуждался тест Тьюринга. Симпозиум организовали Джон Бенден (John Barnden), Марк Бишоп (Mark Bishop), Хьюма Ша и Кевин Ворвик. В числе докладчиков были директор Королевского института баронесса Сьюзан Гринфилд (Susan Greenfield) , Сельмер Брингсорд (Selmer Bringsjord), биограф Тьюринга Эндрю Ходжес (Andrew Hodges) и учёный Оуэн Холланд (Owen Holland). Никакого соглашения о каноническом тесте Тьюринга не появилось, однако Брингсорд предположил, что более крупная премия будет способствовать тому, что тест Тьюринга будет пройден быстрее. Год Алана Тьюринга и Тьюринг-100 в 2012 [ править | править код ] В 2012 году отмечался юбилей Алана Тьюринга. На протяжении всего года проходило множество больших мероприятий. Многие из них проводились в местах, имевших большое значение в жизни Тьюринга: Кембридж, Манчестер и Блетчли Парк. Год Алана Тьюринга Архивная копия от 11 июня 2011 на Wayback Machine курируется организацией TCAC (Turing Centenary Advisory Committee), осуществляющей профессиональную и организационную поддержку мероприятий в 2012 году. Также поддержкой мероприятий занимаются: ACM , ASL , SSAISB , BCS , BCTCS , Блетчи Парк , BMC , BLC , CCS , Association CiE , EACSL , EATCS , FoLLI , IACAP , IACR , KGS и LICS . Для организации мероприятий по празднованию в июне 2012 года столетия со дня рождения Тьюринга создан специальный комитет, задачей которого является донести мысль Тьюринга о разумной машине, отражённую в таких голливудских фильмах, как « Бегущий по лезвию », до широкой публики, включая детей. В работе комитета участвуют: Кевин Ворвик, председатель, Хьюма Ша, координатор, Ян Бланд (Ian Bland), Крис Чапмэн (Chris Chapman), Марк Аллен (Marc Allen), Рори Данлоуп (Rory Dunlop), победители конкурса на получение премии Лёбнера Робби Гарне и Фред Робертс (Fred Roberts). Комитет работает при поддержке организации «Женщины в технике» (Women in Technology) и Daden Ltd. На этом конкурсе россияне, имена которых не разглашались, представили программу « Eugene » [ 6 ] . В 150 проведённых тестах (а по факту пятиминутных разговорах) участвовали пять новейших программ, которые «затерялись» среди 25 обычных людей. Программа «Eugene», изображавшая 13-летнего мальчика, проживающего в Одессе , стала победителем, сумев в 29,2 % своих ответов ввести экзаменаторов в заблуждение. Таким образом, программа не добрала всего 0,8 % для полного прохождения теста. Тест Тьюринга на русском языке, 2015 [ править | править код ] В 2015 году компания « Наносемантика » и Фонд Сколково провели конкурс «Тест Тьюринга на русском языке». Независимые судьи из числа посетителей конференции Startup Village в Москве общались с 8 отобранными экспертным советом роботами и 8 волонтёрами-лингвистами. После 3 минут разговора на русском языке судьи определяли, кто из их собеседников является роботом, а кто нет. Каждый робот провёл по 15 разговоров. В конкурсе победил робот, созданный Иваном Голубевым из Санкт-Петербурга , — «Соня Гусева». 47 % собеседников приняли его за человека [ 7 ] . GPT-4 [ править | править код ] В 2024 году было проведено исследование, в котором 500 участников попросили поговорить с четырьмя респондентами, включая человека, и программу ELIZA, а также GPT-3.5 и GPT-4 (последняя также является основой популярного ИИ-бота ChatGPT ). Разговоры длились пять минут, после чего участники должны были сказать, считают ли они, что разговаривают с человеком или с искусственным интеллектом. Участники в 54% случаев считали GPT-4 человеком, тогда как ELIZA была названы им лишь в 22% случаев. GPT-3.5 набрал 50%, а участника-человек опознали лишь в 67% [ 8 ] . В этом исследовании, как и в вышедшем чуть раньше в этом же году [ 9 ] , исследователи резюмировали прохождение теста Тьюринга большими языковыми моделями на основе GPT-4 [ 10 ] . Варианты теста Тьюринга [ править | править код ] Имитационная игра согласно описанию Тьюринга в статье «Вычислительные машины и разум». Игрок С путём задавания серии вопросов пытается определить, кто из двух других игроков — мужчина, а кто — женщина. Игрок А, мужчина, пытается запутать игрока С, а игрок В пытается помочь С. Первоначальный тест на основе имитационной игры, в котором вместо игрока А играет компьютер. Компьютер теперь должен запутать игрока С, в то время как игрок В продолжает пытаться помочь ведущему. Существуют по крайней мере три основных варианта теста Тьюринга, два из которых были предложены в статье «Вычислительные машины и разум», а третий вариант, по терминологии Сола Трейджера (Saul Traiger), является стандартной интерпретацией. Наряду с тем, что существует определённая дискуссия, соответствует ли современная интерпретация тому, что описывал Тьюринг, либо она является результатом неверного толкования его работ, все три версии не считаются равносильными, их сильные и слабые стороны различаются. Имитационная игра [ править | править код ] Тьюринг, как мы уже знаем, описал простую игру для вечеринок, которая включает в себя минимум трёх игроков. Игрок А — мужчина, игрок В — женщина и игрок С, который играет в качестве ведущего беседу, любого пола. По правилам игры С не видит ни А, ни В и может общаться с ними только посредством письменных сообщений. Задавая вопросы игрокам А и В, С пытается определить, кто из них — мужчина, а кто — женщина. Задачей игрока А является запутать игрока С, чтобы он сделал неправильный вывод. В то же время задачей игрока В является помочь игроку С вынести верное суждение. В той версии, которую С. Г. Стеррет (S. G. Sterret) называет «Первоначальный тест на основе имитационной игры» (Original Imitation Game Test), Тьюринг предлагает, чтобы роль игрока А исполнял компьютер. Таким образом, задачей компьютера является притвориться женщиной, чтобы сбить с толку игрока С. Успешность выполнения подобной задачи оценивается на основе сравнения исходов игры, когда игрок А — компьютер, и исходов, когда игрок А — мужчина. Теперь мы спросим: «Что произойдёт, если машина выступит в качестве игрока А в этой игре?» Будет ли ведущий принимать неправильные решения, когда игра ведётся таким образом, так же часто как если бы в игре принимали участие мужчина и женщина? Эти вопросы заменят наш первоначальный: «Могут ли машины думать?» Оригинальный текст (англ.) We now ask the question, «What will happen when a machine takes the part of A in this game?»  Will the interrogator decide wrongly as often when the game is played like this as he does when the game is played between a man and a woman? These questions replace our original, «Can machines think?» Второй вариант предложен Тьюрингом в той же статье. Как и в «Первоначальном тесте», роль игрока А исполняет компьютер. Различие заключается в том, что роль игрока В может исполнять как мужчина, так и женщина. «Давайте рассмотрим конкретный компьютер. Верно ли то, что модифицируя этот компьютер с целью иметь достаточно места для хранения данных, увеличивая скорость его работы и задавая ему подходящую программу, можно сконструировать такой компьютер, чтобы он удовлетворительно выполнял роль игрока А в имитационной игре, в то время как роль игрока В выполняет мужчина?», — Тьюринг, 1950, стр. 442. В этом варианте оба игрока А и В пытаются склонить ведущего к неверному решению. Стандартная интерпретация [ править | править код ] Главной мыслью данной версии является то, что целью теста Тьюринга является ответ не на вопрос, может ли машина одурачить ведущего, а на вопрос, может ли машина имитировать человека или нет. Несмотря на то что идут споры о том, подразумевался ли этот вариант Тьюрингом или нет, Стеррет считает, что этот вариант Тьюрингом подразумевался и, таким образом, совмещает второй вариант с третьим. В это же время группа оппонентов, включая Трейджера, так не считает. Но это всё равно привело к тому, что можно назвать «стандартной интерпретацией». В этом варианте игрок А — компьютер, игрок В — человек любого пола. Задачей ведущего является теперь не определить, кто из них мужчина и женщина, а кто из них компьютер, а кто — человек. Имитационная игра в сравнении со стандартным тестом Тьюринга [ править | править код ] Существуют разногласия по поводу того, какой же вариант имел в виду Тьюринг. Стеррет настаивает на том, что из работы Тьюринга следуют два различных варианта теста, которые, согласно Тьюрингу, неэквивалентны друг другу. Тест, в котором используется игра для вечеринок и сравнивается доля успехов, называется Первоначальным тестом на основе имитационной игры, в то время как тест, основанный на беседе судьи с человеком и машиной, называют Стандартным тестом Тьюринга, отмечая, что Стеррет приравнивает его к стандартной интерпретации, а не ко второму варианту имитационной игры. Стеррет согласен, что Стандартный тест Тьюринга (STT — Standard Turing Test) имеет недостатки, на которые указывает его критика. Но он считает, что напротив первоначальный тест на основе имитационной игры (OIG Test — Original Imitation Game Test) лишён многих из них в силу ключевых различий: в отличие от STT он не рассматривает поведение, похожее на человеческое, в качестве основного критерия, хотя и учитывает человеческое поведение в качестве признака разумности машины. Человек может не пройти тест OIG, в связи с чем есть мнение, что это является достоинством теста на наличие интеллекта. Неспособность пройти тест означает отсутствие находчивости: в тесте OIG по определению считается, что интеллект связан с находчивостью и не является просто «имитацией поведения человека во время разговора». В общем виде тест OIG можно даже использовать в невербальных вариантах. Тем не менее другие писатели интерпретировали слова Тьюринга как предложение считать саму имитационную игру тестом. Причём не объясняется, как связать это положение и слова Тьюринга о том, что тест, предложенный им на основе игры для вечеринок, базируется на критерии сравнительной частоты успехов в этой имитационной игре, а не на возможности выиграть раунд игры. Должен ли судья знать о компьютере? [ править | править код ] В своих работах Тьюринг не поясняет, знает ли судья о том, что среди участников теста будет компьютер, или нет. Что касается OIG, Тьюринг лишь говорит, что игрока А следует заменить машиной, но умалчивает, известно ли это игроку С или нет. Когда Колби, Ф. Д. Хилф (F. D. Hilf), А. Д. Крамер (A. D. Kramer) тестировали PARRY, они решили, что судьям необязательно знать, что один или несколько собеседников будут компьютерами. Как отмечает А. Седжин (A. Saygin), а также другие специалисты, это накладывает существенный отпечаток на реализацию и результаты теста. Достоинства теста [ править | править код ] Ширина темы [ править | править код ] Сильной стороной теста Тьюринга является то, что можно разговаривать о чём угодно. Тьюринг писал, что «метод вопросов и ответов кажется подходящим для обсуждения почти любой из сфер человеческих интересов, которую мы хотим обсудить». Джон Хогеленд добавил, что «одного понимания слов недостаточно; вам также необходимо разбираться в теме разговора».
Чтобы пройти хорошо поставленный тест Тьюринга, машина должна использовать естественный язык, рассуждать, иметь познания и обучаться. Тест можно усложнить, включив ввод с помощью видео или, например, оборудовав шлюз для передачи предметов: машине придётся продемонстрировать способность к зрению и робототехнике. Все эти задачи вместе отражают основные проблемы, стоящие перед теорией об искусственном интеллекте. Уступчивость и простота [ править | править код ] Сила и привлекательность теста Тьюринга исходит из его простоты. Философы сознания, психологии в современной неврологии неспособны дать определения «интеллект» и «мышление», насколько они являются достаточно точными и вообще применимы к машинам. Без такого определения в центральных вопросах философии об искусственном интеллекте не может быть ответа. Тест Тьюринга, даже если и несовершенен, но по крайней мере обеспечивает то, что это действительно может быть измерено. Как таковой, он является прагматическим решением трудных философских вопросов [ источник не указан 2255 дней ] . В советской психологии Выготский Л. С. и Лурия А. Р. дали вполне чёткие определения «интеллекта» и «мышления» [ 11 ] . Недостатки теста [ править | править код ] Несмотря на все свои достоинства и известность, тест критикуют на нескольких основаниях. Человеческий разум и разум в целом [ править | править код ] Поведение человека и разумное поведение. Направленность теста Тьюринга ярко выражена в сторону человека ( антропоморфизм ). Проверяется только способность машины походить на человека, а не разумность машины вообще. Тест неспособен оценить общий интеллект машины по двум причинам: Иногда поведение человека не поддаётся разумному толкованию. В это же время тест Тьюринга требует, чтобы машина была способна имитировать все виды человеческого поведения, не обращая внимания на то, насколько оно разумно. Он также проверяет способность имитировать такое поведение, какое человек за разумное и не посчитает — например, реакция на оскорбления, соблазн соврать или просто большое количество опечаток. Если машина неспособна с точностью до деталей имитировать поведение человека, опечатки и тому подобное, то она не проходит тест, несмотря на весь тот интеллект, которым она может обладать. Некоторое разумное поведение не присуще человеку. Тест Тьюринга не проверяет высокоинтеллектуальное поведение, например способность решать сложные задачи или выдвигать оригинальные идеи. По сути, тест требует, чтобы машина обманывала: какой бы умной ни была машина, она должна притворяться не слишком умной, чтобы пройти тест. Если же машина способна быстро решить некую вычислительную задачу, непосильную для человека, она по определению провалит тест. Непрактичность [ править | править код ] Стюарт Рассел (Stuart Russel) и Питер Норвиг (Peter Norvig) утверждают, что антропоцентризм теста приводит к тому, что он не может быть по-настоящему полезным при разработке разумных машин. «Тесты по авиационному проектированию и строительству, — строят они аналогию, — не ставят целью своей отрасли создание машин, которые летают точно так же, как летают голуби, что даже сами голуби принимают их за своих» [ 12 ] . Из-за этой непрактичности прохождение теста Тьюринга не является целью ведущих научных или коммерческих исследований (по состоянию на 2009). Сегодняшние исследования в области искусственного интеллекта ставят перед собой более скромные и специфические цели. «Исследователи в области искусственного интеллекта уделяют мало внимания прохождению теста Тьюринга», — отмечают Рассел и Норвиг. Большинство современных исследований в областях, связанных с ИИ, направлены на решение конкретных целей (например, распознавание объектов или логистика ), и проще их проверить, поставив задание напрямую. Тьюринг никогда не предполагал использовать свой тест на практике, в повседневном измерении степени разумности программ; он хотел дать ясный и понятный пример для поддержки обсуждения философии искусственного интеллекта. Следует подчеркнуть, что Тьюринг не раскрывал в развёрнутом виде свои цели и идею создания теста. Исходя из условий прохождения можно предположить, что в его время интеллект человека доминировал во всех областях, то есть был сильнее и быстрее любого другого. В настоящее же время некоторые программы, имитирующие интеллектуальную деятельность, настолько эффективны, что превосходят разум среднестатистического жителя Земли в определённых узких областях. Следовательно, при определённых условиях они могут пройти тест. Реальный интеллект и имитируемый интеллект [ править | править код ] Также тест Тьюринга явно бихевиористичен или функционалистичен : он лишь проверяет, как действует субъект. Машина, проходящая тест, может имитировать поведение человека в разговоре, просто «неинтеллектуально» следуя механическим правилам. Двумя известными контрпримерами, выражающими данную точку зрения, являются « Китайская комната » Сёрля (1980) и «Болван» Неда Блока (Ned Block, 1981). По мнению Сёрля, основной проблемой является определить, «имитирует» ли машина мышление или «на самом деле» мыслит. Даже если тест Тьюринга и является годным для определения наличия интеллекта, Сёрль отмечает, что тест не покажет, что у машины есть разум, сознание, возможность «понимать» или иметь цели, которые имеют какой-то смысл (философы называют это целеполаганием). В своей работе Тьюринг писал по поводу этих аргументов следующее: «Я не хочу создать впечатление, будто я думаю, что у сознания нет никакой загадки. Существует, например, своего рода парадокс, связанный с любой попыткой определить его местонахождение. Но я не думаю, что эти загадки обязательно надо разгадать до того, как мы сможем ответить на вопрос, которому посвящена данная работа». Предсказания [ править | править код ] Тьюринг прогнозировал, что машины в конце концов будут способны пройти тест; фактически он ожидал, что к 2000 году машины с объёмом памяти 10 9 бит (около 119,2 МиБ или 125 МБ ) будут способны обманывать 30 % судей по результатам пятиминутного теста. Также он высказал мысль о том, что словосочетание «думающая машина» больше не будет считаться оксюмороном . Далее он предположил, что машинное обучение будет важным звеном в построении мощных машин, что является правдоподобным среди современных исследователей в области искусственного интеллекта [ 13 ] . Экстраполируя экспоненциальный рост уровня технологии в течение нескольких десятилетий, футурист Рэймонд Курцвейл предположил, что машины, способные пройти тест Тьюринга, будут изготовлены, по грубым оценкам, около 2020 года. Это перекликается с законом Мура . В проект Long Bet Project входит пари стоимостью 20 000 $ между Митчем Капуром (Mitch Kapor — пессимист) и Рэймондом Курцвейлом (оптимист). Смысл пари: пройдёт ли компьютер тест Тьюринга к 2029 году? Определены также некоторые условия пари [ 14 ] . Вариации теста Тьюринга [ править | править код ] Многочисленные версии теста Тьюринга, включая описанные ранее, уже обсуждаются довольно долгое время. Обратный тест Тьюринга и CAPTCHA [ править | править код ] Модификация теста Тьюринга, в которой цель или одну, или более ролей машины и человека поменяли местами, называется обратным тестом Тьюринга. Пример этого теста приведён в работе психоаналитика Уилфреда Биона , который был в особенности восхищён тем, как активизируется мыслительная активность при столкновении с другим разумом. Развивая эту идею, Р. Д. Хиншелвуд (R. D. Hinshelwood) описал разум как «аппарат, распознающий разум», отметив, что это можно считать как бы «дополнением» к тесту Тьюринга. Теперь задачей компьютера будет определить, с кем он беседовал: с человеком или же с другим компьютером. Именно на это дополнение к вопросу и пытался ответить Тьюринг, но, пожалуй, оно вводит достаточно высокий стандарт на то, чтобы определить, может ли машина «думать» так, как мы обычно относим это понятие к человеку. Пример — Искаженная строка smwm CAPTCHA — это разновидность обратного теста Тьюринга. Перед тем как разрешить выполнение некоторого действия на сайте, пользователю выдаётся искажённое изображение с набором цифр и букв и предложение ввести этот набор в специальное поле. Цель этой операции — предотвратить атаки автоматических систем на сайт. Обоснованием подобной операции является то, что пока не существует программ, достаточно мощных для того, чтобы распознать и точно воспроизвести текст с искажённого изображения (или они недоступны рядовым пользователям), поэтому считается, что система, которая смогла это сделать, с высокой вероятностью может считаться человеком. Выводом будет (хотя и не обязательно), что искусственный интеллект пока не создан. Тест Тьюринга со специалистом [ править | править код ] Эта вариация теста описывается следующим образом: ответ машины не должен отличаться от ответа эксперта — специалиста в определённой области знаний. Тест бессмертия [ править | править код ] Тест бессмертия — это вариация теста Тьюринга, которая определяет, качественно ли передан характер человека, а именно возможно ли отличить скопированный характер от характера человека, послужившего его источником. Минимальный интеллектуальный Signal-тест (MIST) [ править | править код ] MIST предложен Крисом Мак-Кинстри (Chris McKinstry). В этой вариации теста Тьюринга разрешены лишь два типа ответов — «да» и «нет». Обычно MIST используют для сбора статистической информации, с помощью которой можно измерить производительность программ, реализующих искусственный интеллект. Мета-тест Тьюринга [ править | править код ] В этой вариации теста субъект (скажем, компьютер) считают разумным, если он создал нечто, что он сам хочет проверить на разумность. Премия Хаттера [ править | править код ] Организаторы премии Хаттера считают, что сжатие текста на естественном языке является трудной задачей для искусственного интеллекта, эквивалентной прохождению теста Тьюринга. Тест по сжатию информации имеет определённые преимущества над большей частью вариантов и вариаций теста Тьюринга: Его результатом является единственное число, по которому можно судить, какая из двух машин «более разумная». Не требуется, чтобы компьютер врал судье — учить компьютеры врать считают плохой идеей. Основными недостатками подобного теста являются: С его помощью невозможно протестировать человека. Неизвестно, какой результат (и есть ли он вообще) эквивалентен прохождению теста Тьюринга (на уровне человека). Другие тесты интеллекта [ править | править код ] Существует множество тестов на уровень интеллекта, которые используют для тестирования людей. Возможно, что их можно использовать для тестирования искусственного интеллекта. Некоторые тесты (например, Си-тест), выведенные из «Колмогоровской сложности», используются для проверки людей и компьютеров. Тест BotPrize [ править | править код ] Двум командам программистов удалось победить в конкурсе BotPrize, который называют «игровой версией» теста Тьюринга. Сообщение о результатах теста приведено на сайте BotPrize, кратко его результаты анализирует NewScientist. Тест BotPrize проходил в виде многопользовательской компьютерной игры (Unreal Tournament 2004), персонажами которой управляли реальные люди или компьютерные алгоритмы [ 15 ] . Женя Густман [ править | править код ] Основная статья: Женя Густман По сообщению Университета Рединга , в тестировании 6 июня 2014 года, организованном Школой системной инженерии [ 16 ] при университете и компаний RoboLaw под руководством профессора Кевина Уорика , полноценный тест Тьюринга впервые в истории был пройден с помощью программы « Eugene Goostman » [ 17 ] [ 18 ] , разработанной в Санкт-Петербурге выходцами из России Владимиром Веселовым и Сергеем Уласенем и выходцем из Украины Евгением Демченко [ 19 ] [ 20 ] . Всего в тестировании участвовали пять суперкомпьютеров . Испытание представляло собой серию пятиминутных письменных диалогов. Тест Тьюринга считался пройденным, если компьютеру удалось бы вводить собеседника (человека) в заблуждение на протяжении хотя бы 30 % суммарного времени. Программа Eugene c результатом 33 % и стала тем устройством, которое искусственным путём воссоздало человеческий интеллект — в данном случае, тринадцатилетнего подростка из Одессы , который «претендует на то, что знает всё на свете, но в силу своего возраста не знает ничего». Это вторая победа программы, однако в 2012 году на конкурсе в честь юбилея Алана Тьюринга (см. выше) она не добрала 0,8 % для полного прохождения теста. Однако критики утверждают, что Женя Густман является лишь «чатботом»: …Машина прикидывается всего лишь ребёнком, ну а полноценное прохождение теста Тьюринга невозможно ею в принципе. Ибо тест всего лишь бихевиористичен; на принципиальный вопрос — мыслит ли машина? — он ответа дать не может… Данные вопросы, конечно, могут обеспечить работой поколения философов-профессионалов, равно как и досугом — обширные круги философов-самоучек. Но вот с точки зрения инженерного дела или бизнеса они никакого смысла не имеют [ 21 ] . Схема Винограда [ править | править код ] Тест Тьюринга, использующий простые, но неоднозначно сформулированные на обычном языке вопросы [ 22 ] . Тесты для учеников школ [ править | править код ] Тест Тьюринга, использующий тестовые задания для учеников начальных и средних классов школы [ 22 ] . Задания по сборке [ править | править код ] Тест Тьюринга, использующий задания по сборке заданной конструкции из набора деталей, используя вербальные, написанные и нарисованные инструкции [ 22 ] . I-Athlon [ править | править код ] Тест Тьюринга, предлагающий выполнить изложение содержания аудиофайла и пересказ сюжета видеоклипа и другие подобные задания [ 22 ] . В искусстве [ править | править код ] Тест Тьюринга играет большую роль в фильме « Из машины » [ 23 ] . BBC издало книгу «Тест Тьюринга» [англ.] См. также [ править | править код ] Китайская комната Премия Лёбнера CAPTCHA « Дознание пилота Пиркса » « Бегущий по лезвию » « Сатурн-3 » « Из машины » « Игра в имитацию » Detroit: Become Human Модель психического состояния человека Примечания [ править | править код ] ↑ Портал искусственного интеллекта (неопр.) . Дата обращения: 13 июля 2012. Архивировано 29 июня 2012 года. ↑ Маркус, Дэвис, 2021 , с. 225. ↑ Jabberwacky Архивировано 11 апреля 2005 года. (англ.) ↑ Elbot Архивная копия от 20 июня 2012 на Wayback Machine (англ.) ↑ Пройти тест Тьюринга не так-то просто Архивная копия от 1 декабря 2011 на Wayback Machine // pcweek.ru ↑ Макарчев, Виталий. Программа "Евгений" почти прошла текст математика Алана Тьюринга . Российские специалисты первыми в мире вплотную приблизились к созданию подлинного искусственного разума (неопр.) . ИТАР-ТАСС (22 августа 2012). Дата обращения: 9 июня 2014. Архивировано 9 июня 2014 года. ↑ Финал «Теста Тьюринга»: подробности и результаты (неопр.) (10 июня 2015). Дата обращения: 15 июня 2015. Архивировано 13 апреля 2021 года. ↑ ИИ становится умнее — чат-бот на базе GPT-4 прошёл тест Тьюринга (рус.) . 3DNews - Daily Digital Digest . Дата обращения: 17 июня 2024. Архивировано 17 июня 2024 года. ↑ Scott, Cameron. Study finds ChatGPT’s latest bot behaves like humans, only better | Stanford School of Humanities and Sciences (англ.) . humsci.stanford.edu . Дата обращения: 17 июня 2024. Архивировано 26 марта 2024 года. ↑ ChatGPT-4 Passes Turing Test, Demonstrating Human-Equivalent Intelligence (неопр.) . Дата обращения: 1 июля 2024. Архивировано 1 июля 2024 года. ↑ Выготский Л. С. , Лурия А. Р. Этюды по истории поведения: Обезьяна. Примитив. Ребёнок. / Предисловие А. Г. Асмолова . — М. : Педагогика-Пресс , 1993. — 224 с. — (Психология). — 30 000 экз. — ISBN 5-7155-0531-3 . Архивировано 1 июля 2014 года. ↑ Рассел С. , Норвиг П. Искусственный интеллект: современный подход = Artificial Intelligence: A Modern Approach / Пер. К. Птицын. — 2-е изд. — Вильямс, 2005. — 1408 p. — 2000 экз. — ISBN 978-5-8459-0887-2 . Архивировано 15 июля 2014 года. ↑ Turing, 1950 , p. 442. ↑ Long Bets — By 2029 no computer — or «machine intelligence» — will have passed the Turing Test (неопр.) . Дата обращения: 10 октября 2009. Архивировано 28 марта 2019 года. ↑ Две программы прошли «игровую версию» теста Тьюринга (неопр.) . Дата обращения: 26 сентября 2012. Архивировано 27 сентября 2012 года. ↑ School of Systems Engineering (неопр.) . Дата обращения: 9 июня 2014. Архивировано 19 июня 2014 года. ↑ http://www.reading.ac.uk/sse/news/sse-newsarticle-2014-06-08.aspx Архивная копия от 14 июля 2014 на Wayback Machine Turing test success marks milestone in computing history
08 June 2014 University of Reading ↑ Ликоспастов, Егор. Тест Тьюринга пройден (неопр.) (8 июня 2014). Дата обращения: 9 июня 2014. Архивировано 8 июня 2014 года. ↑ Российско-украинская компьютерная программа впервые в истории прошла тест Тьюринга Архивная копия от 12 июня 2014 на Wayback Machine // Телеканал « Дождь », 9 июня 2014 ↑ Михаил Ваннах (2014-06-09). Как одессит Густман прошёл тест Тьюринга . Компьютерра . Архивировано 11 июня 2014 . Дата обращения: 7 марта 2017 . ↑ Ваннах, Михаил. Как одессит Густман прошёл тест Тьюринга . Умные машины (неопр.) . Компьютерра (9 июня 2014). — «Более того, имеет место масса критических оценок...» Дата обращения: 11 июня 2014. Архивировано 11 июня 2014 года. ↑ 1 2 3 4 Гэри Маркус Человек ли я? Архивная копия от 7 июля 2017 на Wayback Machine // В мире науки . — 2017. — № 5-6. — С. 72 — 77. ↑ Mark Kermode, Observer film critic. Ex Machina review – dazzling sci-fi thriller (англ.) // The Guardian . — 2015. — 25 January. — ISSN 0261-3077 . Литература [ править | править код ] Тьюринг А. М. Вычислительные машины и разум. // В сб.: Хофштадер Д., Деннет Д. Глаз разума. — Самара: Бахрах-М, 2003. — С. 47-59 Alan Turing , « Computing Machinery and Intelligence », Mind, vol. LIX, no. 236, October 1950, pp. 433—460 Roger Penrose «The Emperor’s New Mind» Статья Дж. Оппи (G. Oppy) и Д. Дави (D. Dowe) о тесте Тьюринга (англ.) из Стэнфордской Философской Энциклопедии Гэри Маркус, Эрнест Дэвис. Искусственный интеллект: Перезагрузка. Как создать машинный разум, которому действительно можно доверять = Rebooting AI: Building Artificial Intelligence We Can Trust. — М. : Интеллектуальная Литература, 2021. — 304 с. — ISBN 978-5-907394-93-3 . Ссылки [ править | править код ] Минимальный тест Тьюринга: докажи одним словом, что ты – человек Профессор предлагает альтернативу Тесту Тьюринга // Викиновости, 5 декабря 2014 «Turing Test: 50 Years Later» (англ.) — обзор 50-летней работы над тестом Тьюринга, с точки зрения 2000 г. Щипков Б. Р. Анти-Тьюринг. Критика термина «искусственный интеллект» и теста Тьюринга «Кто за стеной?» Философская притча. Центрнаучфильм , 1977 г., режиссёр Семён Райтбурт . Ссылки на внешние ресурсы Словари и энциклопедии Большая датская Большая каталанская Стэнфордская философская Britannica (онлайн) В библиографических каталогах BNF : 16644546h GND : 4770569-3 J9U : 987007549165905171 LCCN : sh93008808 SUDOC : 166106372 Искусственный интеллект История Вычислительные машины и разум Зима искусственного интеллекта Бум искусственного интеллекта Джорджтаунский эксперимент Дартмутский семинар Отчёт Лайтхилла Регламент ЕС Гонка вооружений в области искусственного интеллекта Холодная война за искусственный интеллект Философия Тест Тьюринга Китайская комната Сильный и слабый искусственные интеллекты Дружественный искусственный интеллект Этика искусственного интеллекта Проблема контроля Направления Агентный подход Адаптивное управление Генеративный ИИ Инженерия знаний Модель жизнеспособной системы Машинное обучение Нейронная сеть Нечёткая логика Обработка естественного языка Персональный искусственный интеллект Распознавание образов Роевой интеллект Символический ИИ Эволюционные алгоритмы Экспертная система Применение Голосовое управление Задача классификации Классификация документов Кластеризация документов Кластерный анализ Локальный поиск Машинный перевод Оптическое распознавание символов Распознавание речи Распознавание рукописного ввода Игровой ИИ Исследователи Чарлз Бэббидж Владимир Вапник Джозеф Вейценбаум Норберт Винер Виктор Глушков Владимир Городецкий Рэймонд Курцвейл Ян Лекун Алексей Ляпунов Джон Маккарти Марвин Мински Аллен Ньюэлл Сеймур Пейперт Джуда Перл Гермоген Поспелов Дмитрий Поспелов Фрэнк Розенблатт Герберт Саймон Алан Тьюринг Патрик Уинстон Виктор Финн Сергей Фомин Демис Хассабис Джеффри Хинтон Ноам Хомский Клод Шеннон Эндрю Ын Элиезер Юдковский Источник — https://ru.wikipedia.org/w/index.php?title=Тест_Тьюринга&oldid=144099255 Категории : Информатика Философия искусственного интеллекта 1950 год в науке Алан Тьюринг Скрытые категории: Википедия:Cite web (не указан язык) Страницы, использующие волшебные ссылки ISBN Википедия:Статьи к переработке с октября 2024 года Википедия:Статьи к переработке Википедия:Статьи с шаблонами недостатков по алфавиту Википедия:Статьи для обновления с июня 2024 года Википедия:Статьи для обновления Википедия:Статьи без источников (не распределённые по типам) Википедия:Нет источников с января 2019 Википедия:Статьи с утверждениями без источников более 14 дней Навигация Поиск